# 📚 소스 타입별 실제 데이터 출처 매핑

## 목표
각 소스 타입에 대해 **실제 외부 데이터를 수집할 수 있는 출처**를 정의하고, 수집 방법을 제안합니다.

---

## 📂 파인다이닝 / 스시 오마카세

### 1️⃣ michelin_review (미쉐린 가이드)

#### 🌐 데이터 출처
1. **미쉐린 가이드 공식 사이트**
   - URL: `https://guide.michelin.com/kr/ko`
   - 매장별 페이지 예시: `https://guide.michelin.com/kr/ko/seoul-region/seoul/restaurant/[매장명]`
   - 수집 내용: 별점, 가격대, 평가 내용, 특징

2. **네이버 검색**
   - 쿼리: `"{매장명}" 미쉐린`
   - 뉴스 기사에서 미쉐린 관련 언급 추출

#### 🔧 수집 방법
```python
# 방법 1: 직접 크롤링 (robots.txt 확인 필요)
# 방법 2: 검색 API + 뉴스 기사 수집
# 방법 3: LLM에게 요약 요청 (현재 방식)
```

#### ⚠️ 제약사항
- 미쉐린 등재 매장만 가능
- 크롤링 제한 가능성
- 매장명 매칭 정확도

---

### 2️⃣ blueribbon_review (블루리본 서베이)

#### 🌐 데이터 출처
1. **블루리본 서베이 공식 사이트**
   - URL: `https://www.bluer.co.kr`
   - 매장 검색 → 상세 정보 페이지
   - 수집 내용: 등급, 점수, 평가 내용

2. **뉴스 기사**
   - 블루리본 발표 시즌에 언론 보도
   - 쿼리: `"{매장명}" 블루리본`

#### 🔧 수집 방법
```python
# 방법 1: bluer.co.kr 크롤링
# 방법 2: 네이버 뉴스 검색 API
# 방법 3: LLM 요약
```

#### ⚠️ 제약사항
- 블루리본 등재 매장만 가능
- 사이트 구조 변경 시 크롤러 수정 필요

---

### 3️⃣ chef_interview (셰프 인터뷰)

#### 🌐 데이터 출처
1. **식당 매거진/미디어**
   - 매거진B
   - 데일리 매거진
   - 식신로드
   - W Korea, 엘르 등

2. **레스토랑 공식 웹사이트**
   - "About Chef" 섹션
   - "Our Story" 페이지

3. **네이버/구글 뉴스**
   - 쿼리: `"{매장명}" 셰프 인터뷰`
   - 쿼리: `"{셰프명}" 인터뷰`

4. **YouTube**
   - 맛집 인터뷰 채널
   - 셰프 직접 출연 영상 → 자막 추출

#### 🔧 수집 방법
```python
# 방법 1: 네이버 뉴스 검색 API
# 방법 2: 공식 웹사이트 크롤링
# 방법 3: YouTube Transcript API
```

#### ⚠️ 제약사항
- 인터뷰 기사가 없는 매장 많음
- 셰프명을 모를 경우 검색 어려움

---

### 4️⃣ course_description (코스 구성)

#### 🌐 데이터 출처
1. **레스토랑 공식 웹사이트**
   - 메뉴 페이지
   - 코스 설명

2. **예약 플랫폼**
   - 캐치테이블: `https://app.catchtable.co.kr`
   - 테이블링: `https://www.tabling.co.kr`
   - 시그니처 메뉴, 코스 정보

3. **네이버 플레이스 / 카카오맵**
   - 메뉴 탭
   - 리뷰에서 코스 언급 추출

#### 🔧 수집 방법
```python
# 방법 1: 공식 웹사이트 크롤링
# 방법 2: 캐치테이블/테이블링 API (비공개)
# 방법 3: 네이버 플레이스 크롤링
```

#### ⚠️ 제약사항
- 공식 웹사이트가 없는 매장 많음
- 예약 플랫폼 API는 비공개

---

### 5️⃣ brand_philosophy (철학/공간/전통)

#### 🌐 데이터 출처
1. **레스토랑 공식 웹사이트**
   - "About Us", "Philosophy" 섹션
   - "Our Story", "Concept" 페이지

2. **인테리어/디자인 매거진**
   - 월간 디자인
   - 엘르 데코
   - 레스토랑 소개 기사

3. **SNS (Instagram, 블로그)**
   - 공식 계정 소개글
   - 오픈 당시 보도자료

#### 🔧 수집 방법
```python
# 방법 1: 공식 웹사이트 크롤링
# 방법 2: 뉴스 검색 API
# 방법 3: Instagram API (제한적)
```

---

## 📂 웨이팅 핫플레이스

### 1️⃣ signature_menu (시그니처 메뉴)

#### 🌐 데이터 출처
1. **네이버 플레이스 / 카카오맵**
   - 메뉴 탭
   - 대표 메뉴, 인기 메뉴

2. **리뷰 사이트**
   - 네이버 블로그 리뷰
   - 망고플레이트
   - 다이닝코드

3. **SNS**
   - Instagram 해시태그: `#{매장명}`
   - 자주 언급되는 메뉴 추출

#### 🔧 수집 방법
```python
# 방법 1: 네이버 플레이스 크롤링
# 방법 2: 블로그 검색 API + 메뉴명 추출
# 방법 3: Instagram Graph API
```

---

### 2️⃣ atmosphere (분위기/공간)

#### 🌐 데이터 출처
1. **네이버 플레이스 리뷰**
   - "분위기", "인테리어" 키워드 필터링
   - 방문자 리뷰 요약

2. **블로그 리뷰**
   - 네이버 블로그 검색
   - "분위기", "공간", "인테리어" 언급 부분 추출

3. **Google Maps 리뷰**
   - 영문 리뷰 포함 (관광객 관점)

#### 🔧 수집 방법
```python
# 방법 1: 네이버 플레이스 API (비공개)
# 방법 2: 블로그 검색 API + 키워드 필터링
# 방법 3: Google Places API
```

---

### 3️⃣ popularity (인기도/웨이팅)

#### 🌐 데이터 출처
1. **예약/웨이팅 플랫폼**
   - 캐치테이블, 테이블링
   - 웨이팅 시간 정보

2. **SNS 언급량**
   - Instagram 해시태그 개수
   - 블로그 포스팅 수

3. **리뷰 사이트**
   - 네이버 플레이스 리뷰 개수
   - 망고플레이트 저장 수

#### 🔧 수집 방법
```python
# 방법 1: 플랫폼별 API (제한적)
# 방법 2: 네이버 블로그 검색 API (건수)
# 방법 3: Instagram Graph API (해시태그 카운트)
```

---

### 4️⃣ price_value (가격/가성비)

#### 🌐 데이터 출처
1. **네이버 플레이스 / 카카오맵**
   - 메뉴판 사진
   - 가격 정보

2. **리뷰**
   - "가성비", "가격" 키워드 필터링
   - 1인당 평균 비용 언급

#### 🔧 수집 방법
```python
# 방법 1: 네이버 플레이스 메뉴 정보
# 방법 2: 리뷰에서 가격 정보 추출 (NER)
```

---

### 5️⃣ location_access (위치/접근성)

#### 🌐 데이터 출처
1. **네이버 지도 / 카카오맵**
   - 주소, 좌표
   - 교통 정보 (지하철역 거리)

2. **리뷰**
   - "주차", "찾기 어려움", "역에서 가까움" 등 키워드

#### 🔧 수집 방법
```python
# 방법 1: Naver/Kakao Map API
# 방법 2: Google Maps API
```

---

## 📂 중저가 예약 매장

### 1️⃣ menu_composition (메뉴 구성)
→ **파인다이닝의 course_description과 동일 출처**

### 2️⃣ value_proposition (가성비/가치)
→ **웨이팅 핫플의 price_value + 품질 평가 추가**

### 3️⃣ dining_atmosphere (분위기/경험)
→ **웨이팅 핫플의 atmosphere + 서비스 평가 추가**

### 4️⃣ reservation_parking (예약/주차)
→ **캐치테이블/테이블링 + 네이버 플레이스 주차 정보**

### 5️⃣ chef_approach (셰프 접근법)
→ **파인다이닝의 chef_interview 축소판**

---

## 🎯 실제 구현 가능한 데이터 소스 우선순위

### ✅ Tier 1: 즉시 크롤링 가능
1. **네이버 블로그 검색 API**
   - 모든 소스 타입에 활용 가능
   - 키워드 기반 검색 후 필터링
   - **가장 범용적**

2. **네이버 플레이스 크롤링**
   - 메뉴, 가격, 위치, 주차 정보
   - 리뷰 수집 가능

3. **Google Maps API**
   - 위치, 리뷰, 영업시간
   - 유료이지만 안정적

### ⚠️ Tier 2: 제한적 크롤링
1. **미쉐린 가이드 웹사이트**
   - robots.txt 확인 필요
   - 등재 매장만 가능

2. **블루리본 서베이 웹사이트**
   - 로그인 필요 가능성
   - 등재 매장만 가능

3. **레스토랑 공식 웹사이트**
   - 구조가 제각각
   - 없는 매장 많음

### ❌ Tier 3: 접근 어려움
1. **캐치테이블/테이블링 API**
   - 비공개 API
   - 크롤링 시 법적 이슈 가능성

2. **Instagram API**
   - 개인 계정 제한
   - 비즈니스 계정 필요

---

## 💡 추천 구현 전략

### 전략 A: 네이버 블로그 중심 (가장 현실적)
```python
def collect_source_from_blogs(shop_name, source_type):
    # 1. 네이버 블로그 검색
    keyword = f"{shop_name} {source_keywords[source_type]}"
    blogs = search_naver_blog(keyword, display=10)

    # 2. 상위 블로그 크롤링
    texts = [crawl_blog_content(blog['link']) for blog in blogs]

    # 3. LLM으로 소스 타입에 맞게 요약
    return summarize_with_llm(texts, source_type)
```

**장점:**
- ✅ API 공식 제공 (네이버 개발자 센터)
- ✅ 모든 매장 적용 가능
- ✅ 실제 외부 데이터 (블로거 방문 후기)

**단점:**
- ⚠️ 블로그 품질 편차
- ⚠️ 광고성 블로그 필터링 필요

---

### 전략 B: 하이브리드 (품질 최우선)
```python
def collect_source(shop_name, source_type):
    # 1순위: 공식 출처 (미쉐린, 블루리본)
    result = try_official_source(shop_name, source_type)
    if result: return result

    # 2순위: 네이버 블로그
    result = collect_from_blogs(shop_name, source_type)
    if result: return result

    # 3순위: LLM 지식 (폴백)
    return collect_with_llm_knowledge(shop_name, source_type)
```

**장점:**
- ✅ 최고 품질 우선
- ✅ 실패 시 대체 방안 있음
- ✅ 모든 매장 커버

**단점:**
- ⚠️ 구현 복잡도 높음
- ⚠️ 처리 시간 증가

---

## 다음 단계

어떤 방향으로 진행하시겠습니까?

1. **전략 A (네이버 블로그 중심)** 구현
   - 네이버 검색 API 신청
   - 블로그 크롤러 개발
   - 소스 타입별 키워드 매핑

2. **전략 B (하이브리드)** 설계
   - 각 소스별 1순위 출처 크롤러 구현
   - 폴백 체인 구축

3. **현재 LLM 지식 방식 유지**
   - 이름만 "RAG" → "Knowledge Base"로 변경
   - 검증 강화

---

생성일: 2025-11-11
대상: 15가지 소스 타입
목적: 실제 외부 데이터 수집 출처 매핑
