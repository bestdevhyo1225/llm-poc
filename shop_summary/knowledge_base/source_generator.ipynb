{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Phase 2A: ì›ë³¸ ì†ŒìŠ¤ ìë™ ìƒì„± ë…¸íŠ¸ë¶ (LLM ì§€ì‹ ê¸°ë°˜)\n\nì´ ë…¸íŠ¸ë¶ì€ **ë§¤ì¥ëª…ë§Œ ì…ë ¥**í•˜ë©´ **LLMì˜ ë‚´ì¥ ì§€ì‹**ì„ í™œìš©í•˜ì—¬ 5ê°€ì§€ ì†ŒìŠ¤ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.\n\n## LLM ì§€ì‹ ê¸°ë°˜ ìƒì„±\n\nLLMì´ í•™ìŠµí•œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ 5ê°€ì§€ ì†ŒìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:\n\n1. ğŸŒŸ **ë¯¸ì‰ë¦° ê°€ì´ë“œ** - LLM ì§€ì‹ (ë³„ì , í‰ê°€)\n2. ğŸ”µ **ë¸”ë£¨ë¦¬ë³¸ ì„œë² ì´** - LLM ì§€ì‹ (í‰ê°€, íŠ¹ì§•)\n3. ğŸ‘¨â€ğŸ³ **ì…°í”„ ì¸í„°ë·°** - LLM ì§€ì‹ (ì² í•™, ì¡°ë¦¬ ë°©ì‹)\n4. ğŸ½ï¸ **ì½”ìŠ¤ êµ¬ì„±** - LLM ì§€ì‹ (ë©”ë‰´, ì‹œê·¸ë‹ˆì²˜)\n5. ğŸ›ï¸ **ì² í•™/ê³µê°„/ì „í†µ** - LLM ì§€ì‹ (ë¸Œëœë“œ, ì¸í…Œë¦¬ì–´)\n\n## ì¥ì \n\n### ğŸ’° ì™„ì „ ë¬´ë£Œ\n- ì›¹ í¬ë¡¤ë§ ë¶ˆí•„ìš”\n- API í˜¸ì¶œ ë¹„ìš© ì—†ìŒ\n- LLM í† í° ë¹„ìš©ë§Œ (~$0.02/ë§¤ì¥)\n\n### âš¡ ë§¤ìš° ë¹ ë¦„\n- ì›¹ ìš”ì²­ ì—†ìŒ\n- LLM ì‘ë‹µë§Œ ëŒ€ê¸°\n- ì´ ì²˜ë¦¬ ì‹œê°„: 10-15ì´ˆ/ë§¤ì¥\n\n### ğŸ”§ ìœ ì§€ë³´ìˆ˜ ë¶ˆí•„ìš”\n- ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ ì˜í–¥ ì—†ìŒ\n- í¬ë¡¤ëŸ¬ ê´€ë¦¬ ë¶ˆí•„ìš”\n- ì•ˆì •ì  ì‘ë™\n\n### ğŸ“¦ ê°„ë‹¨í•œ êµ¬í˜„\n- ë³µì¡í•œ í¬ë¡¤ë§ ë¡œì§ ì—†ìŒ\n- Selenium/ChromeDriver ë¶ˆí•„ìš”\n- ì½”ë“œ 100ì¤„ ì´í•˜\n\n## ì£¼ì˜ì‚¬í•­\n\n### âš ï¸ í• ë£¨ì‹œë„¤ì´ì…˜ ê°€ëŠ¥\n- LLMì´ \"í•™ìŠµí•œ ì§€ì‹\"ìœ¼ë¡œ ë‹µë³€\n- ì‹¤ì œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n- ê²€ì¦ í•„ìš”\n\n### âš ï¸ ìµœì‹  ì •ë³´ ë¶€ì¡±\n- 2024ë…„ ì´ì „ ì •ë³´ ê¸°ë°˜\n- ì‹ ê·œ ì˜¤í”ˆ ë§¤ì¥ ì •ë³´ ì—†ì„ ìˆ˜ ìˆìŒ\n- ìµœì‹  ë³„ì /ë¦¬ë·° ë°˜ì˜ ì•ˆë¨\n\n### âš ï¸ ì°¸ê³ ìš©ìœ¼ë¡œ í™œìš©\n- ì´ˆì•ˆ/í”„ë¡œí† íƒ€ì…ìš©\n- ì¤‘ìš” ì •ë³´ëŠ” ìˆ˜ë™ ê²€ì¦ ê¶Œì¥\n- ê³µì‹ ì¸ì¦ ì •ë³´ëŠ” ë³„ë„ í™•ì¸\n\n## ì í•©í•œ ì‚¬ìš© ì¼€ì´ìŠ¤\n\nâœ… **í”„ë¡œí† íƒ€ì…/POC**\n- ë¹ ë¥¸ ë°ì´í„° ìƒì„±\n- ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n\nâœ… **ëŒ€ëµì  ì •ë³´ ìˆ˜ì§‘**\n- ë§¤ì¥ ë¶„ë¥˜\n- ì´ˆê¸° ë°ì´í„°ì…‹ êµ¬ì¶•\n\nâœ… **ì°¸ê³  ìë£Œ ìƒì„±**\n- ì‚¬ëŒì´ ë³´ì •í•  ì´ˆì•ˆ\n- ì¼ë°˜ì ì¸ ì„¤ëª… ìƒì„±\n\n## ë¹„ìš©\n\n| í•­ëª© | ë¹„ìš© |\n|------|------|\n| LLM í† í° (5ê°œ ì†ŒìŠ¤) | ~$0.02/ë§¤ì¥ |\n| **ì´ ë¹„ìš©** | **$0.02/ë§¤ì¥** |\n\n**100ê°œ ë§¤ì¥: $2**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 1: íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-cloud-aiplatform google-genai python-dotenv pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 2: ë¼ì´ë¸ŒëŸ¬ë¦¬ Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import vertexai\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ Import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 3: Vertex AI ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = \"wad-dw\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "print(f\"âœ… Vertex AI ì´ˆê¸°í™” ì™„ë£Œ: {PROJECT_ID} ({LOCATION})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 4: LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘\n",
    "# ========================================\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "\n",
    "print(\"âœ… LLM ì§€ì‹ ê¸°ë°˜ ëª¨ë“œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "print(f\"   - ëª¨ë¸: {MODEL_NAME}\")\n",
    "print(f\"   - ìˆ˜ì§‘ ë°©ë²•: LLM ë‚´ì¥ ì§€ì‹ë§Œ ì‚¬ìš©\")\n",
    "print(f\"   - ë¹„ìš©: í† í° ë¹„ìš©ë§Œ (~$0.02/ë§¤ì¥)\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 5ê°€ì§€ ì†ŒìŠ¤ íƒ€ì… ì •ì˜\n",
    "# ========================================\n",
    "\n",
    "SOURCE_CONFIGS = {\n",
    "    \"michelin_review\": {\n",
    "        \"name\": \"ë¯¸ì‰ë¦° ê°€ì´ë“œ\",\n",
    "        \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì— ëŒ€í•œ ë¯¸ì‰ë¦° ê°€ì´ë“œ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "        - ë¯¸ì‰ë¦° ë³„ì  (0-3ìŠ¤íƒ€, ë¹• êµ¬ë¥´ë§ ë“±)\n",
    "        - ê°€ê²©ëŒ€\n",
    "        - ì£¼ìš” í‰ê°€ ë‚´ìš©\n",
    "        - ë ˆìŠ¤í† ë‘ íŠ¹ì§•\n",
    "\n",
    "        300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "    },\n",
    "    \"blueribbon_review\": {\n",
    "        \"name\": \"ë¸”ë£¨ë¦¬ë³¸ ì„œë² ì´\",\n",
    "        \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì— ëŒ€í•œ ë¸”ë£¨ë¦¬ë³¸ ì„œë² ì´ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "        - ë¸”ë£¨ë¦¬ë³¸ ë“±ê¸‰/ì ìˆ˜\n",
    "        - í‰ê°€ ë‚´ìš©\n",
    "        - ë ˆìŠ¤í† ë‘ íŠ¹ì§•\n",
    "\n",
    "        300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "    },\n",
    "    \"chef_interview\": {\n",
    "        \"name\": \"ì…°í”„ ì¸í„°ë·°\",\n",
    "        \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ ì…°í”„ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "        - ì…°í”„ ì´ë¦„ ë° ê²½ë ¥\n",
    "        - ìš”ë¦¬ ì² í•™\n",
    "        - ì‹ì¬ë£Œ í™œìš© ë°©ì‹\n",
    "        - ì¡°ë¦¬ ê¸°ë²• ë° ìŠ¤íƒ€ì¼\n",
    "\n",
    "        300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "    },\n",
    "    \"course_description\": {\n",
    "        \"name\": \"ì½”ìŠ¤ êµ¬ì„±\",\n",
    "        \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ë©”ë‰´ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "        - ì½”ìŠ¤ êµ¬ì„± (ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ìœ¼ë¡œ)\n",
    "        - ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´\n",
    "        - ëŒ€í‘œ ìš”ë¦¬\n",
    "        - ê°€ê²©ëŒ€\n",
    "\n",
    "        300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "    },\n",
    "    \"brand_philosophy\": {\n",
    "        \"name\": \"ì² í•™/ê³µê°„/ì „í†µ\",\n",
    "        \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ë¸Œëœë“œ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "        - ë¸Œëœë“œ ì² í•™ ë° ìŠ¤í† ë¦¬\n",
    "        - ê³µê°„ ë””ìì¸ ë° ë¶„ìœ„ê¸°\n",
    "        - ì¸í…Œë¦¬ì–´ íŠ¹ì§•\n",
    "        - ì „í†µ ê¸°ë²• í™œìš©\n",
    "\n",
    "        300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘ í•¨ìˆ˜\n",
    "# ========================================\n",
    "\n",
    "def collect_with_llm_knowledge(shop_name: str, source_type: str, config: dict) -> dict:\n",
    "    \"\"\"LLMì˜ ë‚´ì¥ ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •ë³´ ìˆ˜ì§‘\"\"\"\n",
    "    try:\n",
    "        full_prompt = f\"\"\"\n",
    "        ë§¤ì¥ëª…: {shop_name}\n",
    "\n",
    "        ë‹¹ì‹ ì˜ í•™ìŠµëœ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
    "\n",
    "        {config['prompt']}\n",
    "\n",
    "        ì¤‘ìš”:\n",
    "        - í•™ìŠµëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "        - í™•ì‹¤í•œ ë‚´ìš©ë§Œ í¬í•¨í•˜ì„¸ìš”\n",
    "        - ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”\n",
    "        - ì •ë³´ê°€ ì—†ê±°ë‚˜ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”\n",
    "\n",
    "        ì¶œë ¥ í˜•ì‹ (JSON):\n",
    "        {{\n",
    "        \"text\": \"ë‚´ìš©...\",\n",
    "        \"found\": true\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL_NAME,\n",
    "            contents=full_prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.3,\n",
    "                max_output_tokens=2048,\n",
    "                response_mime_type=\"application/json\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response.text)\n",
    "        \n",
    "        if result.get(\"found\") and result.get(\"text\"):\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"text\": result[\"text\"],\n",
    "                \"url\": \"\",\n",
    "                \"method\": \"llm_knowledge\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"reason\": \"LLMì´ í™•ì‹¤í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŒ\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"reason\": f\"LLM ì˜¤ë¥˜: {str(e)}\"\n",
    "        }\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# ë§¤ì¥ë³„ ìë™ ìˆ˜ì§‘ (5ê°€ì§€ ì†ŒìŠ¤)\n",
    "# ========================================\n",
    "\n",
    "def auto_collect_shop_sources(shop_seq: int, shop_name: str, category: str) -> dict:\n",
    "    \"\"\"í•œ ë§¤ì¥ì— ëŒ€í•´ 5ê°€ì§€ ì†ŒìŠ¤ë¥¼ LLM ì§€ì‹ìœ¼ë¡œ ìˆ˜ì§‘\"\"\"\n",
    "    print(f\"\\nğŸ” {shop_name} ì •ë³´ ìˆ˜ì§‘ ì¤‘ (LLM ì§€ì‹)...\")\n",
    "    print(\"â”€\" * 80)\n",
    "    \n",
    "    sources = []\n",
    "    \n",
    "    for source_type, config in SOURCE_CONFIGS.items():\n",
    "        print(f\"   [{config['name']}]...\", end=\" \")\n",
    "        \n",
    "        result = collect_with_llm_knowledge(shop_name, source_type, config)\n",
    "        \n",
    "        if result[\"success\"]:\n",
    "            sources.append({\n",
    "                \"source_type\": source_type,\n",
    "                \"text\": result[\"text\"],\n",
    "                \"url\": result.get(\"url\", \"\"),\n",
    "                \"collected_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "                \"collection_method\": \"llm_knowledge\"\n",
    "            })\n",
    "            print(f\"âœ… ({len(result['text'])}ì)\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ {result['reason']}\")\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    return {\n",
    "        \"shop_seq\": shop_seq,\n",
    "        \"shop_name\": shop_name,\n",
    "        \"category\": category,\n",
    "        \"sources\": sources\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"\\nâœ… LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"   - ìˆ˜ì§‘ ì†ŒìŠ¤: {len(SOURCE_CONFIGS)}ê°€ì§€\")\n",
    "print(f\"   - ëª¨ë‘ LLM ë‚´ì¥ ì§€ì‹ ì‚¬ìš©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 5: ë§¤ì¥ ë¦¬ìŠ¤íŠ¸ ì…ë ¥\n",
    "\n",
    "ìˆ˜ì§‘í•  ë§¤ì¥ì˜ shop_seqì™€ shop_nameë§Œ ì…ë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë§¤ì¥ ë¦¬ìŠ¤íŠ¸ ì…ë ¥\n",
    "# ========================================\n",
    "\n",
    "# ìˆ˜ì§‘í•  ë§¤ì¥ ë¦¬ìŠ¤íŠ¸ (shop_seq + shop_name + category)\n",
    "BATCH_SHOPS = [\n",
    "    {\"shop_seq\": 1, \"shop_name\": \"ëª¨ìˆ˜\", \"category\": \"fine_dining\"},\n",
    "    {\"shop_seq\": 2, \"shop_name\": \"ë°ê¸€ìŠ¤\", \"category\": \"fine_dining\"},\n",
    "    {\"shop_seq\": 3, \"shop_name\": \"ìŠ¤ì‹œ ì†Œë¼\", \"category\": \"fine_dining\"},\n",
    "    # ì¶”ê°€ ë§¤ì¥ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”...\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“‹ ìë™ ìˆ˜ì§‘ ëŒ€ìƒ ë§¤ì¥\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nì´ {len(BATCH_SHOPS)}ê°œ ë§¤ì¥:\\n\")\n",
    "\n",
    "for idx, shop in enumerate(BATCH_SHOPS, 1):\n",
    "    print(f\"   [{idx}] {shop['shop_name']} (seq: {shop['shop_seq']}, category: {shop['category']})\")\n",
    "\n",
    "print(f\"\\nê° ë§¤ì¥ë‹¹ 5ê°€ì§€ ì†ŒìŠ¤ ìë™ ìˆ˜ì§‘ (LLM ì§€ì‹):\")\n",
    "for source_type, config in SOURCE_CONFIGS.items():\n",
    "    print(f\"   â€¢ {config['name']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 6: LLM ì§€ì‹ ê¸°ë°˜ ìë™ ìˆ˜ì§‘ ì‹¤í–‰\n",
    "\n",
    "âš ï¸ LLMì˜ ë‚´ì¥ ì§€ì‹ë§Œ ì‚¬ìš©í•˜ì—¬ 5ê°€ì§€ ì†ŒìŠ¤ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# LLM ì§€ì‹ ê¸°ë°˜ ìë™ ìˆ˜ì§‘ ì‹¤í–‰\n",
    "# ========================================\n",
    "\n",
    "print(\"ğŸš€ LLM ì§€ì‹ ê¸°ë°˜ ìë™ ìˆ˜ì§‘ ì‹œì‘\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“š ëª¨ë“  ì†ŒìŠ¤: LLM ë‚´ì¥ ì§€ì‹ í™œìš©\")\n",
    "print(\"âš¡ ë¹ ë¥¸ ì²˜ë¦¬: 10-15ì´ˆ/ë§¤ì¥\")\n",
    "print(\"ğŸ’° ì €ë ´í•œ ë¹„ìš©: ~$0.02/ë§¤ì¥\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "collected_data = []\n",
    "collection_stats = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, shop in enumerate(BATCH_SHOPS, 1):\n",
    "    print(f\"\\n[{idx}/{len(BATCH_SHOPS)}] {shop['shop_name']} ({shop['category']})\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    shop_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘ ì‹¤í–‰\n",
    "        result = auto_collect_shop_sources(\n",
    "            shop_seq=shop[\"shop_seq\"],\n",
    "            shop_name=shop[\"shop_name\"],\n",
    "            category=shop[\"category\"]\n",
    "        )\n",
    "        \n",
    "        shop_elapsed = time.time() - shop_start\n",
    "        \n",
    "        # í†µê³„\n",
    "        num_sources = len(result.get(\"sources\", []))\n",
    "        total_chars = sum(len(s[\"text\"]) for s in result.get(\"sources\", []))\n",
    "        \n",
    "        print(f\"\\nâœ… ì™„ë£Œ: {num_sources}/5ê°œ ì†ŒìŠ¤ ìˆ˜ì§‘ ({shop_elapsed:.1f}ì´ˆ)\")\n",
    "        print(f\"   - ì¹´í…Œê³ ë¦¬: {result.get('category')}\")\n",
    "        print(f\"   - ì´ í…ìŠ¤íŠ¸: {total_chars:,}ì\")\n",
    "        \n",
    "        collected_data.append(result)\n",
    "        collection_stats.append({\n",
    "            \"shop_name\": shop[\"shop_name\"],\n",
    "            \"category\": shop[\"category\"],\n",
    "            \"status\": \"success\",\n",
    "            \"num_sources\": num_sources,\n",
    "            \"total_chars\": total_chars,\n",
    "            \"elapsed_time\": shop_elapsed\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ì˜¤ë¥˜: {e}\")\n",
    "        collection_stats.append({\n",
    "            \"shop_name\": shop[\"shop_name\"],\n",
    "            \"category\": shop.get(\"category\", \"unknown\"),\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "    \n",
    "    # ë‹¤ìŒ ë§¤ì¥ê¹Œì§€ ëŒ€ê¸°\n",
    "    if idx < len(BATCH_SHOPS):\n",
    "        wait_seconds = 2\n",
    "        print(f\"\\nâ³ ë‹¤ìŒ ë§¤ì¥ê¹Œì§€ {wait_seconds}ì´ˆ ëŒ€ê¸°...\")\n",
    "        time.sleep(wait_seconds)\n",
    "\n",
    "total_elapsed = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nâœ… LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘ ì™„ë£Œ (ì´ {total_elapsed:.1f}ì´ˆ = {total_elapsed/60:.1f}ë¶„)\\n\")\n",
    "\n",
    "# í†µê³„\n",
    "success_count = sum(1 for s in collection_stats if s.get(\"status\") == \"success\")\n",
    "total_sources = sum(s.get(\"num_sources\", 0) for s in collection_stats)\n",
    "\n",
    "print(f\"ğŸ“Š í†µê³„:\")\n",
    "print(f\"   - ì„±ê³µ: {success_count}/{len(BATCH_SHOPS)}ê°œ ë§¤ì¥\")\n",
    "print(f\"   - ì´ ì†ŒìŠ¤: {total_sources}ê°œ (í‰ê·  {total_sources/success_count if success_count > 0 else 0:.1f}ê°œ/ë§¤ì¥)\")\n",
    "print(f\"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_elapsed / len(BATCH_SHOPS):.1f}ì´ˆ/ë§¤ì¥\")\n",
    "\n",
    "# ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬\n",
    "if collected_data:\n",
    "    category_counts = {}\n",
    "    for data in collected_data:\n",
    "        cat = data.get(\"category\", \"unknown\")\n",
    "        category_counts[cat] = category_counts.get(cat, 0) + 1\n",
    "    \n",
    "    print(f\"\\n   ì¹´í…Œê³ ë¦¬ë³„:\")\n",
    "    for cat, count in category_counts.items():\n",
    "        print(f\"   - {cat}: {count}ê°œ\")\n",
    "\n",
    "# ë¹„ìš© ê³„ì‚°\n",
    "llm_tokens_estimate = total_sources * 2000  # ì†ŒìŠ¤ë‹¹ ì•½ 2K tokens\n",
    "cost_estimate = (llm_tokens_estimate / 1000000) * 1.25  # Input token cost for Gemini 2.5 Pro\n",
    "print(f\"\\nğŸ’° ì˜ˆìƒ ë¹„ìš©:\")\n",
    "print(f\"   - LLM í† í°: ì•½ ${cost_estimate:.3f}\")\n",
    "print(f\"   - **ì´ ë¹„ìš©: ì•½ ${cost_estimate:.3f}** (ë§¤ì¥ë‹¹ ${cost_estimate/success_count if success_count > 0 else 0:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ë‹¤ìŒ ë‹¨ê³„\n\n### ì›Œí¬í”Œë¡œìš°\n1. âœ… **source_generator.ipynb** (í˜„ì¬) - ë§¤ì¥ëª… ì…ë ¥ â†’ LLM ì§€ì‹ ìƒì„± â†’ JSON\n2. â­ï¸ **source_validator.ipynb** - JSON ê²€ì¦ ë° í†µí•© (ì„ íƒ)\n3. â­ï¸ **source_indexer.ipynb** - ì²­í‚¹ ë° ë²¡í„° DB ì¸ë±ì‹±\n\n### ìƒì„±ëœ íŒŒì¼\n- `collected_sources_llm_[timestamp].json` - ìƒì„±ëœ ì›ë³¸ ì†ŒìŠ¤ ë°ì´í„°\n- `collection_stats_[timestamp].csv` - ìƒì„± í†µê³„\n\n### LLM ì§€ì‹ ê¸°ë°˜ ë°©ì‹ ìš”ì•½\n\n| ì†ŒìŠ¤ | ìƒì„± ë°©ë²• | ì •í™•ë„ | ë¹„ìš© |\n|------|----------|--------|------|\n| ğŸŒŸ ë¯¸ì‰ë¦° ê°€ì´ë“œ | LLM ì§€ì‹ | â­â­â­ | ~$0.004 |\n| ğŸ”µ ë¸”ë£¨ë¦¬ë³¸ ì„œë² ì´ | LLM ì§€ì‹ | â­â­â­ | ~$0.004 |\n| ğŸ‘¨â€ğŸ³ ì…°í”„ ì¸í„°ë·° | LLM ì§€ì‹ | â­â­â­ | ~$0.004 |\n| ğŸ½ï¸ ì½”ìŠ¤ êµ¬ì„± | LLM ì§€ì‹ | â­â­â­ | ~$0.004 |\n| ğŸ›ï¸ ì² í•™/ê³µê°„/ì „í†µ | LLM ì§€ì‹ | â­â­â­ | ~$0.004 |\n\n**ì´ ë¹„ìš©: ë§¤ì¥ë‹¹ ì•½ $0.02 (100ê°œ = $2)**\n\n### ì¥ì \n- âœ… **ì™„ì „ ë¬´ë£Œ ì¸í”„ë¼** (API í˜¸ì¶œ ì—†ìŒ, í¬ë¡¤ë§ ì—†ìŒ)\n- âœ… **ë¹ ë¥¸ ì²˜ë¦¬** (10-15ì´ˆ/ë§¤ì¥)\n- âœ… **ìœ ì§€ë³´ìˆ˜ ë¶ˆí•„ìš”** (ì‚¬ì´íŠ¸ ë³€ê²½ ì˜í–¥ ì—†ìŒ)\n- âœ… **ê°„ë‹¨í•œ ì½”ë“œ** (100ì¤„ ì´í•˜)\n\n### ì£¼ì˜ì‚¬í•­\n- âš ï¸ **í• ë£¨ì‹œë„¤ì´ì…˜ ê°€ëŠ¥** - LLMì´ ì˜ëª»ëœ ì •ë³´ ìƒì„±í•  ìˆ˜ ìˆìŒ\n- âš ï¸ **ìµœì‹  ì •ë³´ ë¶€ì¡±** - 2024ë…„ ì´ì „ ë°ì´í„° ê¸°ë°˜\n- âš ï¸ **ì°¸ê³ ìš©ìœ¼ë¡œ í™œìš©** - ì¤‘ìš” ì •ë³´ëŠ” ìˆ˜ë™ ê²€ì¦ í•„ìš”\n\n### ì í•©í•œ ì‚¬ìš© ì¼€ì´ìŠ¤\n- í”„ë¡œí† íƒ€ì…/POC\n- ëŒ€ëµì  ì •ë³´ ìˆ˜ì§‘\n- ì‚¬ëŒì´ ë³´ì •í•  ì´ˆì•ˆ ìƒì„±"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ìˆ˜ì§‘ í’ˆì§ˆ ê²€ì¦\n",
    "# ========================================\n",
    "\n",
    "if collected_data:\n",
    "    print(\"ğŸ” ìˆ˜ì§‘ í’ˆì§ˆ ê²€ì¦\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for shop in collected_data:\n",
    "        shop_name = shop.get(\"shop_name\", \"Unknown\")\n",
    "        category = shop.get(\"category\", \"unknown\")\n",
    "        sources = shop.get(\"sources\", [])\n",
    "        \n",
    "        print(f\"\\nğŸ“ {shop_name} ({category})\")\n",
    "        print(\"â”€\" * 80)\n",
    "        \n",
    "        # ì†ŒìŠ¤ íƒ€ì…ë³„ í†µê³„\n",
    "        source_types = {}\n",
    "        total_chars = 0\n",
    "        \n",
    "        for source in sources:\n",
    "            stype = source.get(\"source_type\", \"unknown\")\n",
    "            text = source.get(\"text\", \"\")\n",
    "            text_len = len(text)\n",
    "            \n",
    "            source_types[stype] = source_types.get(stype, 0) + 1\n",
    "            total_chars += text_len\n",
    "        \n",
    "        print(f\"   ì´ ì†ŒìŠ¤: {len(sources)}/5ê°œ\")\n",
    "        print(f\"   ì´ í…ìŠ¤íŠ¸: {total_chars:,}ì\")\n",
    "        print(f\"   í‰ê·  ê¸¸ì´: {total_chars // len(sources) if sources else 0:,}ì/ì†ŒìŠ¤\")\n",
    "        \n",
    "        print(f\"\\n   ìˆ˜ì§‘ëœ ì†ŒìŠ¤:\")\n",
    "        for stype, count in sorted(source_types.items()):\n",
    "            source_name = SOURCE_CONFIGS.get(stype, {}).get(\"name\", stype)\n",
    "            print(f\"      âœ… {source_name}: {count}ê°œ\")\n",
    "        \n",
    "        # ëˆ„ë½ëœ ì†ŒìŠ¤ í™•ì¸\n",
    "        missing = set(SOURCE_CONFIGS.keys()) - set(source_types.keys())\n",
    "        if missing:\n",
    "            print(f\"\\n   âš ï¸ ëˆ„ë½ëœ ì†ŒìŠ¤:\")\n",
    "            for stype in missing:\n",
    "                source_name = SOURCE_CONFIGS[stype][\"name\"]\n",
    "                print(f\"      âŒ {source_name}\")\n",
    "        \n",
    "        # ê²½ê³ \n",
    "        if len(sources) < 3:\n",
    "            print(f\"\\n   âš ï¸ ì†ŒìŠ¤ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤ (ìµœì†Œ 3ê°œ ê¶Œì¥)\")\n",
    "        \n",
    "        if total_chars < 500:\n",
    "            print(f\"\\n   âš ï¸ ì „ì²´ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ìµœì†Œ 500ì ê¶Œì¥)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "else:\n",
    "    print(\"âš ï¸ ê²€ì¦í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 8: ìˆ˜ì§‘ í’ˆì§ˆ ê²€ì¦ (ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ========================================\n# JSON íŒŒì¼ ì €ì¥\n# ========================================\n\nif collected_data:\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    filename = f\"collected_sources_llm_{timestamp}.json\"\n    \n    # JSON ì €ì¥\n    with open(filename, 'w', encoding='utf-8') as f:\n        json.dump(collected_data, f, ensure_ascii=False, indent=2)\n    \n    file_size = len(json.dumps(collected_data, ensure_ascii=False))\n    \n    print(f\"ğŸ’¾ JSON ì €ì¥ ì™„ë£Œ: {filename}\")\n    print(f\"   - ë§¤ì¥ ìˆ˜: {len(collected_data)}ê°œ\")\n    print(f\"   - íŒŒì¼ í¬ê¸°: {file_size:,} bytes ({file_size / 1024:.1f} KB)\")\n    \n    # í†µê³„ CSVë„ ì €ì¥\n    import pandas as pd\n    df_stats = pd.DataFrame(collection_stats)\n    csv_filename = f\"collection_stats_{timestamp}.csv\"\n    df_stats.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n    \n    print(f\"ğŸ“Š í†µê³„ íŒŒì¼ ì €ì¥: {csv_filename}\")\n    \n    print(f\"\\nâœ… ë‹¤ìŒ ë‹¨ê³„:\")\n    print(f\"   1. source_validator.ipynbì—ì„œ ê²€ì¦ (ì„ íƒ)\")\n    print(f\"   2. source_indexer.ipynbì—ì„œ ë²¡í„° DB ì¸ë±ì‹±\")\nelse:\n    print(\"âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 7: JSON íŒŒì¼ë¡œ ì €ì¥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}