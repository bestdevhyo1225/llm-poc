{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”„ í†µí•© ì†ŒìŠ¤ íŒŒì´í”„ë¼ì¸ ë…¸íŠ¸ë¶\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸**ì„ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤:\n",
    "\n",
    "```\n",
    "Generator â†’ Validator â†’ Indexer\n",
    "```\n",
    "\n",
    "## 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ê°œìš”\n",
    "\n",
    "### ğŸ“ PHASE 1: ì†ŒìŠ¤ ìƒì„± (Generator)\n",
    "- LLMì˜ ë‚´ì¥ ì§€ì‹ì„ í™œìš©í•˜ì—¬ 5ê°€ì§€ ì›ë³¸ ì†ŒìŠ¤ ìë™ ìƒì„±\n",
    "- ì…ë ¥: shop_seq, shop_name, category\n",
    "- ì¶œë ¥: collected_data (ë©”ëª¨ë¦¬)\n",
    "\n",
    "### âœ… PHASE 2: ë°ì´í„° ê²€ì¦ (Validator)\n",
    "- ìƒì„±ëœ ì†ŒìŠ¤ ë°ì´í„°ì˜ ìœ íš¨ì„± ê²€ì¦\n",
    "- í•„ìˆ˜ í•„ë“œ, ë°ì´í„° íƒ€ì…, í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸\n",
    "- ì¶œë ¥: ê²€ì¦ëœ collected_data (ë©”ëª¨ë¦¬)\n",
    "\n",
    "### ğŸ—„ï¸ PHASE 3: ë²¡í„° DB ì¸ë±ì‹± (Indexer)\n",
    "- ì†ŒìŠ¤ íƒ€ì…ë³„ ì²­í‚¹ ì „ëµ ì ìš©\n",
    "- 768ì°¨ì› ì„ë² ë”© ìƒì„±\n",
    "- Chroma ë²¡í„° DBì— ì €ì¥ (ì¹´í…Œê³ ë¦¬ë³„ ë…ë¦½ ì»¬ë ‰ì…˜)\n",
    "\n",
    "## ì¥ì \n",
    "\n",
    "âœ… **ë‹¨ì¼ ì‹¤í–‰**: í•œ ë²ˆì— ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰  \n",
    "âœ… **ëª…í™•í•œ êµ¬ë¶„**: 3ë‹¨ê³„ê°€ ì‹œê°ì ìœ¼ë¡œ ëª…í™•í•˜ê²Œ êµ¬ë¶„ë¨  \n",
    "âœ… **ë©”ëª¨ë¦¬ ê³µìœ **: JSON íŒŒì¼ I/O ì—†ì´ ë©”ëª¨ë¦¬ì—ì„œ ë°ì´í„° ì „ë‹¬  \n",
    "âœ… **ìœ ì§€ë³´ìˆ˜ ìš©ì´**: í•œ íŒŒì¼ì—ì„œ ëª¨ë“  ë¡œì§ ê´€ë¦¬  \n",
    "\n",
    "## ì‚¬ìš© ë°©ë²•\n",
    "\n",
    "1. ì„¹ì…˜ 5ì—ì„œ ë§¤ì¥ ë¦¬ìŠ¤íŠ¸ ì…ë ¥ (`BATCH_SHOPS`)\n",
    "2. ìˆœì°¨ì ìœ¼ë¡œ ëª¨ë“  ì…€ ì‹¤í–‰ (Run All)\n",
    "3. ê° Phaseì˜ ê²°ê³¼ í™•ì¸\n",
    "4. ìµœì¢… ë²¡í„° DBì— ì¸ë±ì‹± ì™„ë£Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 1: íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-cloud-aiplatform google-genai python-dotenv chromadb langchain langchain-text-splitters pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 2: ë¼ì´ë¸ŒëŸ¬ë¦¬ Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vertexai\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import chromadb\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing import List, Dict\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ Import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 3: Vertex AI ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = \"wad-dw\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "print(f\"âœ… Vertex AI ì´ˆê¸°í™” ì™„ë£Œ: {PROJECT_ID} ({LOCATION})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ PHASE 1: ì†ŒìŠ¤ ìƒì„± (Generator)\n",
    "\n",
    "LLMì˜ ë‚´ì¥ ì§€ì‹ì„ í™œìš©í•˜ì—¬ 5ê°€ì§€ ì›ë³¸ ì†ŒìŠ¤ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 4: LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘\n",
    "# ========================================\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "\n",
    "print(\"âœ… LLM ì§€ì‹ ê¸°ë°˜ ëª¨ë“œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "print(f\"   - ëª¨ë¸: {MODEL_NAME}\")\n",
    "print(f\"   - ìˆ˜ì§‘ ë°©ë²•: LLM ë‚´ì¥ ì§€ì‹ë§Œ ì‚¬ìš©\")\n",
    "print(f\"   - ë¹„ìš©: í† í° ë¹„ìš©ë§Œ (~$0.02/ë§¤ì¥)\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# ì¹´í…Œê³ ë¦¬ë³„ ì†ŒìŠ¤ íƒ€ì… ì •ì˜\n",
    "# ========================================\n",
    "\n",
    "CATEGORY_SOURCE_CONFIGS = {\n",
    "    \"fine_dining\": {\n",
    "        \"michelin_review\": {\n",
    "            \"name\": \"ë¯¸ì‰ë¦° ê°€ì´ë“œ\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì— ëŒ€í•œ ë¯¸ì‰ë¦° ê°€ì´ë“œ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ë¯¸ì‰ë¦° ë³„ì  (0-3ìŠ¤íƒ€, ë¹• êµ¬ë¥´ë§ ë“±)\n",
    "            - ê°€ê²©ëŒ€\n",
    "            - ì£¼ìš” í‰ê°€ ë‚´ìš©\n",
    "            - ë ˆìŠ¤í† ë‘ íŠ¹ì§•\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"blueribbon_review\": {\n",
    "            \"name\": \"ë¸”ë£¨ë¦¬ë³¸ ì„œë² ì´\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì— ëŒ€í•œ ë¸”ë£¨ë¦¬ë³¸ ì„œë² ì´ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ë¸”ë£¨ë¦¬ë³¸ ë“±ê¸‰/ì ìˆ˜\n",
    "            - í‰ê°€ ë‚´ìš©\n",
    "            - ë ˆìŠ¤í† ë‘ íŠ¹ì§•\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"chef_interview\": {\n",
    "            \"name\": \"ì…°í”„ ì¸í„°ë·°\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ ì…°í”„ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ì…°í”„ ì´ë¦„ ë° ê²½ë ¥\n",
    "            - ìš”ë¦¬ ì² í•™\n",
    "            - ì‹ì¬ë£Œ í™œìš© ë°©ì‹\n",
    "            - ì¡°ë¦¬ ê¸°ë²• ë° ìŠ¤íƒ€ì¼\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"course_description\": {\n",
    "            \"name\": \"ì½”ìŠ¤ êµ¬ì„±\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ë©”ë‰´ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ì½”ìŠ¤ êµ¬ì„± (ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ìœ¼ë¡œ)\n",
    "            - ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´\n",
    "            - ëŒ€í‘œ ìš”ë¦¬\n",
    "            - ê°€ê²©ëŒ€\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"brand_philosophy\": {\n",
    "            \"name\": \"ì² í•™/ê³µê°„/ì „í†µ\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ë¸Œëœë“œ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ë¸Œëœë“œ ì² í•™ ë° ìŠ¤í† ë¦¬\n",
    "            - ê³µê°„ ë””ìì¸ ë° ë¶„ìœ„ê¸°\n",
    "            - ì¸í…Œë¦¬ì–´ íŠ¹ì§•\n",
    "            - ì „í†µ ê¸°ë²• í™œìš©\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"waiting_hotplace\": {\n",
    "        \"signature_menu\": {\n",
    "            \"name\": \"ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´ì™€ ì¸ê¸° ë©”ë‰´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ëŒ€í‘œ ë©”ë‰´ ë° ì‹œê·¸ë‹ˆì²˜ ìš”ë¦¬\n",
    "            - ë©”ë‰´ë³„ íŠ¹ì§•ê³¼ ì¸ê¸° ì´ìœ \n",
    "            - SNSì—ì„œ í™”ì œê°€ ëœ ë©”ë‰´\n",
    "            - ì¶”ì²œ ë©”ë‰´ ì¡°í•©\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"atmosphere\": {\n",
    "            \"name\": \"ë¶„ìœ„ê¸°/ê³µê°„\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ë¶„ìœ„ê¸°ì™€ ê³µê°„ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ì¸í…Œë¦¬ì–´ ìŠ¤íƒ€ì¼ê³¼ ë¶„ìœ„ê¸°\n",
    "            - ì¢Œì„ ë°°ì¹˜ ë° ê³µê°„ êµ¬ì„±\n",
    "            - ì¸ìŠ¤íƒ€ê·¸ë˜ë¨¸ë¸”í•œ í¬ì¸íŠ¸\n",
    "            - ë°©ë¬¸ê° ì—°ë ¹ëŒ€ ë° ëª©ì \n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"popularity\": {\n",
    "            \"name\": \"ì¸ê¸°ë„/ì›¨ì´íŒ…\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ì¸ê¸°ë„ì™€ ì›¨ì´íŒ… ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - í‰ê·  ì›¨ì´íŒ… ì‹œê°„\n",
    "            - í”¼í¬ ì‹œê°„ëŒ€ ë° í•œì í•œ ì‹œê°„ëŒ€\n",
    "            - SNS ì–¸ê¸‰ëŸ‰ ë° ë¦¬ë·° ë°˜ì‘\n",
    "            - ì¸ê¸° ë¹„ê²°ê³¼ í•«í”Œë ˆì´ìŠ¤ ìš”ì†Œ\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"price_value\": {\n",
    "            \"name\": \"ê°€ê²©/ê°€ì„±ë¹„\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ê°€ê²©ëŒ€ì™€ ê°€ì„±ë¹„ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ì£¼ìš” ë©”ë‰´ ê°€ê²©ëŒ€\n",
    "            - 1ì¸ë‹¹ í‰ê·  ì˜ˆì‚°\n",
    "            - ê°€ì„±ë¹„ í‰ê°€ ë° ê°€ê²© ëŒ€ë¹„ ë§Œì¡±ë„\n",
    "            - ì¶”ê°€ ë¹„ìš© (ì„œë¹„ìŠ¤ ì°¨ì§€, ìŒë£Œ ë“±)\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"location_access\": {\n",
    "            \"name\": \"ìœ„ì¹˜/ì ‘ê·¼ì„±\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ìœ„ì¹˜ì™€ ì ‘ê·¼ì„± ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ì •í™•í•œ ìœ„ì¹˜ ë° ì£¼ë³€ ëœë“œë§ˆí¬\n",
    "            - ëŒ€ì¤‘êµí†µ ì ‘ê·¼ì„± (ì§€í•˜ì² ì—­, ë²„ìŠ¤ ë“±)\n",
    "            - ì£¼ì°¨ ê°€ëŠ¥ ì—¬ë¶€ ë° ì£¼ì°¨ ì •ë³´\n",
    "            - ì£¼ë³€ ê´€ê´‘ì§€ë‚˜ í•¨ê»˜ ë°©ë¬¸í•˜ê¸° ì¢‹ì€ ì¥ì†Œ\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"mid_to_low\": {\n",
    "        \"menu_composition\": {\n",
    "            \"name\": \"ë©”ë‰´ êµ¬ì„±\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ë©”ë‰´ êµ¬ì„±ì„ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ë° êµ¬ì„±\n",
    "            - ì½”ìŠ¤ ë©”ë‰´ ë˜ëŠ” ë‹¨í’ˆ ë©”ë‰´ ì •ë³´\n",
    "            - ê³„ì ˆ ë©”ë‰´ ë° ì •ê¸° ë³€ê²½ ì—¬ë¶€\n",
    "            - ë©”ë‰´ ë‹¤ì–‘ì„± ë° ì„ íƒ í­\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"value_proposition\": {\n",
    "            \"name\": \"ê°€ì„±ë¹„/ê°€ì¹˜\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ê°€ì„±ë¹„ì™€ ê°€ì¹˜ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ê°€ê²©ëŒ€ (1ì¸ë‹¹ í‰ê·  ë¹„ìš©)\n",
    "            - ê°€ê²© ëŒ€ë¹„ í’ˆì§ˆ ë° ì–‘\n",
    "            - ì˜ˆì•½ ê³ ê° ëŒ€ìƒ í˜œíƒì´ë‚˜ íŠ¹ë³„ ë©”ë‰´\n",
    "            - ê°€ì„±ë¹„ í¬ì¸íŠ¸ ë° ì¶”ì²œ ì´ìœ \n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"dining_atmosphere\": {\n",
    "            \"name\": \"ë¶„ìœ„ê¸°/ê²½í—˜\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ì‹ì‚¬ ë¶„ìœ„ê¸°ì™€ ê²½í—˜ì„ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ë ˆìŠ¤í† ë‘ ë¶„ìœ„ê¸° (ìºì£¼ì–¼, ê²©ì‹, ë¡œë§¨í‹± ë“±)\n",
    "            - ì í•©í•œ ë°©ë¬¸ ëª©ì  (ë°ì´íŠ¸, ê°€ì¡± ëª¨ì„, ë¹„ì¦ˆë‹ˆìŠ¤ ë“±)\n",
    "            - ì„œë¹„ìŠ¤ ìˆ˜ì¤€ ë° íŠ¹ì§•\n",
    "            - íŠ¹ë³„í•œ ê²½í—˜ ìš”ì†Œ\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"reservation_parking\": {\n",
    "            \"name\": \"ì˜ˆì•½/ì£¼ì°¨\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ì˜ ì˜ˆì•½ê³¼ ì£¼ì°¨ ì •ë³´ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ì˜ˆì•½ ë°©ë²• ë° ë‚œì´ë„\n",
    "            - ì˜ˆì•½ í•„ìˆ˜ ì—¬ë¶€ ë° ë‹¹ì¼ ì˜ˆì•½ ê°€ëŠ¥ ì—¬ë¶€\n",
    "            - ì£¼ì°¨ ì‹œì„¤ (ë°œë ›, ìì²´ ì£¼ì°¨ì¥, ì£¼ë³€ ì£¼ì°¨ì¥)\n",
    "            - ì˜ˆì•½ ì‹œ ìœ ì˜ì‚¬í•­\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        },\n",
    "        \"chef_approach\": {\n",
    "            \"name\": \"ì…°í”„ ì ‘ê·¼ë²•\",\n",
    "            \"prompt\": \"\"\"ì´ ë ˆìŠ¤í† ë‘ ì…°í”„ì˜ ìš”ë¦¬ ì ‘ê·¼ë²•ì„ ìš”ì•½í•˜ì„¸ìš”:\n",
    "            - ì…°í”„ì˜ ë°°ê²½ ë° ê²½ë ¥ (ê°„ëµíˆ)\n",
    "            - ìš”ë¦¬ ìŠ¤íƒ€ì¼ ë° íŠ¹ì§•\n",
    "            - ì‹ì¬ë£Œ ì„ íƒ ë° í™œìš© ë°©ì‹\n",
    "            - ì…°í”„ì˜ ì² í•™ì´ ë©”ë‰´ì— ë°˜ì˜ëœ ë¶€ë¶„\n",
    "\n",
    "            300-800ìë¡œ ì‘ì„±í•˜ì„¸ìš”. ì •ë³´ê°€ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”.\"\"\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘ í•¨ìˆ˜ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)\n",
    "# ========================================\n",
    "\n",
    "def collect_with_llm_knowledge(shop_name: str, source_type: str, config: dict, max_retries: int = 2) -> dict:\n",
    "    \"\"\"LLMì˜ ë‚´ì¥ ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •ë³´ ìˆ˜ì§‘ (ìë™ ì¬ì‹œë„ í¬í•¨)\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            full_prompt = f\"\"\"\n",
    "            ë§¤ì¥ëª…: {shop_name}\n",
    "\n",
    "            ë‹¹ì‹ ì˜ í•™ìŠµëœ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
    "\n",
    "            {config['prompt']}\n",
    "\n",
    "            ì¤‘ìš”:\n",
    "            - í•™ìŠµëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "            - í™•ì‹¤í•œ ë‚´ìš©ë§Œ í¬í•¨í•˜ì„¸ìš”\n",
    "            - ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”\n",
    "            - ì •ë³´ê°€ ì—†ê±°ë‚˜ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ foundë¥¼ falseë¡œ ì„¤ì •í•˜ì„¸ìš”\n",
    "            - JSON ë¬¸ìì—´ ë‚´ë¶€ì˜ ë”°ì˜´í‘œëŠ” ë°˜ë“œì‹œ ë°±ìŠ¬ë˜ì‹œë¡œ ì´ìŠ¤ì¼€ì´í”„í•˜ì„¸ìš” (ì˜ˆ: \\\\\" )\n",
    "            - ì¤„ë°”ê¿ˆì€ \\\\nìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”\n",
    "\n",
    "            ì¶œë ¥ í˜•ì‹ (JSON):\n",
    "            {{\n",
    "            \"text\": \"ë‚´ìš©...\",\n",
    "            \"found\": true\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            response = client.models.generate_content(\n",
    "                model=MODEL_NAME,\n",
    "                contents=full_prompt,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    temperature=0.3,\n",
    "                    max_output_tokens=2048,\n",
    "                    response_mime_type=\"application/json\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # JSON íŒŒì‹± ì‹œë„\n",
    "            result = json.loads(response.text)\n",
    "            \n",
    "            if result.get(\"found\") and result.get(\"text\"):\n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"text\": result[\"text\"],\n",
    "                    \"url\": \"\",\n",
    "                    \"method\": \"llm_knowledge\"\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"reason\": \"LLMì´ í™•ì‹¤í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŒ\"\n",
    "                }\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                # ì¬ì‹œë„\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            else:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"reason\": f\"JSON íŒŒì‹± ì˜¤ë¥˜ (ì¬ì‹œë„ {max_retries}íšŒ ì‹¤íŒ¨): {str(e)}\"\n",
    "                }\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                # ì¬ì‹œë„\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            else:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"reason\": f\"LLM ì˜¤ë¥˜ (ì¬ì‹œë„ {max_retries}íšŒ ì‹¤íŒ¨): {str(e)}\"\n",
    "                }\n",
    "    \n",
    "    return {\n",
    "        \"success\": False,\n",
    "        \"reason\": \"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜\"\n",
    "    }\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# ë§¤ì¥ë³„ ìë™ ìˆ˜ì§‘ (ì¹´í…Œê³ ë¦¬ë³„ ì†ŒìŠ¤)\n",
    "# ========================================\n",
    "\n",
    "def auto_collect_shop_sources(shop_seq: int, shop_name: str, category: str) -> dict:\n",
    "    \"\"\"í•œ ë§¤ì¥ì— ëŒ€í•´ ì¹´í…Œê³ ë¦¬ë³„ ì†ŒìŠ¤ë¥¼ LLM ì§€ì‹ìœ¼ë¡œ ìˆ˜ì§‘\"\"\"\n",
    "    print(f\"\\nğŸ” {shop_name} ì •ë³´ ìˆ˜ì§‘ ì¤‘ (LLM ì§€ì‹)...\")\n",
    "    print(\"â”€\" * 80)\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ì†ŒìŠ¤ ì„¤ì • ê°€ì ¸ì˜¤ê¸°\n",
    "    source_configs = CATEGORY_SOURCE_CONFIGS.get(category)\n",
    "    \n",
    "    if not source_configs:\n",
    "        print(f\"   âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬: {category}\")\n",
    "        print(f\"   ì§€ì› ì¹´í…Œê³ ë¦¬: {', '.join(CATEGORY_SOURCE_CONFIGS.keys())}\")\n",
    "        return {\n",
    "            \"shop_seq\": shop_seq,\n",
    "            \"shop_name\": shop_name,\n",
    "            \"category\": category,\n",
    "            \"sources\": []\n",
    "        }\n",
    "    \n",
    "    sources = []\n",
    "    \n",
    "    for source_type, config in source_configs.items():\n",
    "        print(f\"   [{config['name']}]...\", end=\" \")\n",
    "        \n",
    "        result = collect_with_llm_knowledge(shop_name, source_type, config)\n",
    "        \n",
    "        if result[\"success\"]:\n",
    "            sources.append({\n",
    "                \"source_type\": source_type,\n",
    "                \"text\": result[\"text\"],\n",
    "                \"url\": result.get(\"url\", \"\"),\n",
    "                \"collected_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "                \"collection_method\": \"llm_knowledge\"\n",
    "            })\n",
    "            print(f\"âœ… ({len(result['text'])}ì)\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ {result['reason']}\")\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    return {\n",
    "        \"shop_seq\": shop_seq,\n",
    "        \"shop_name\": shop_name,\n",
    "        \"category\": category,\n",
    "        \"sources\": sources\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"\\nâœ… LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"   - ì¹´í…Œê³ ë¦¬ë³„ ì†ŒìŠ¤ íƒ€ì…:\")\n",
    "for category, sources in CATEGORY_SOURCE_CONFIGS.items():\n",
    "    print(f\"     â€¢ {category}: {len(sources)}ê°€ì§€ ì†ŒìŠ¤\")\n",
    "print(f\"   - ëª¨ë‘ LLM ë‚´ì¥ ì§€ì‹ ì‚¬ìš©\")\n",
    "print(f\"   - ìë™ ì¬ì‹œë„: ìµœëŒ€ 2íšŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 5: ë§¤ì¥ ë¦¬ìŠ¤íŠ¸ ì…ë ¥\n",
    "\n",
    "ìˆ˜ì§‘í•  ë§¤ì¥ì˜ shop_seq, shop_name, categoryë¥¼ ì…ë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë§¤ì¥ ë¦¬ìŠ¤íŠ¸ ì…ë ¥\n",
    "# ========================================\n",
    "\n",
    "# ìˆ˜ì§‘í•  ë§¤ì¥ ë¦¬ìŠ¤íŠ¸ (shop_seq + shop_name + category)\n",
    "BATCH_SHOPS = [\n",
    "    {\"shop_seq\": 1, \"shop_name\": \"ëª¨ìˆ˜\", \"category\": \"fine_dining\"},\n",
    "    {\"shop_seq\": 2, \"shop_name\": \"ë°ê¸€ìŠ¤\", \"category\": \"fine_dining\"},\n",
    "    {\"shop_seq\": 3, \"shop_name\": \"ìŠ¤ì‹œ ì†Œë¼\", \"category\": \"fine_dining\"},\n",
    "    # ì¶”ê°€ ë§¤ì¥ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”...\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“‹ ìë™ ìˆ˜ì§‘ ëŒ€ìƒ ë§¤ì¥\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nì´ {len(BATCH_SHOPS)}ê°œ ë§¤ì¥:\\n\")\n",
    "\n",
    "for idx, shop in enumerate(BATCH_SHOPS, 1):\n",
    "    print(f\"   [{idx}] {shop['shop_name']} (seq: {shop['shop_seq']}, category: {shop['category']})\")\n",
    "\n",
    "print(f\"\\nì¹´í…Œê³ ë¦¬ë³„ ìë™ ìˆ˜ì§‘ ì†ŒìŠ¤ íƒ€ì… (LLM ì§€ì‹):\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "for category, source_configs in CATEGORY_SOURCE_CONFIGS.items():\n",
    "    print(f\"\\nğŸ“‚ {category} ({len(source_configs)}ê°€ì§€):\")\n",
    "    for source_type, config in source_configs.items():\n",
    "        print(f\"   â€¢ {config['name']} ({source_type})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 6: LLM ì§€ì‹ ê¸°ë°˜ ìë™ ìˆ˜ì§‘ ì‹¤í–‰\n",
    "\n",
    "âš ï¸ LLMì˜ ë‚´ì¥ ì§€ì‹ë§Œ ì‚¬ìš©í•˜ì—¬ 5ê°€ì§€ ì†ŒìŠ¤ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# LLM ì§€ì‹ ê¸°ë°˜ ìë™ ìˆ˜ì§‘ ì‹¤í–‰\n",
    "# ========================================\n",
    "\n",
    "print(\"ğŸš€ LLM ì§€ì‹ ê¸°ë°˜ ìë™ ìˆ˜ì§‘ ì‹œì‘\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“š ëª¨ë“  ì†ŒìŠ¤: LLM ë‚´ì¥ ì§€ì‹ í™œìš©\")\n",
    "print(\"âš¡ ë¹ ë¥¸ ì²˜ë¦¬: 10-15ì´ˆ/ë§¤ì¥\")\n",
    "print(\"ğŸ’° ì €ë ´í•œ ë¹„ìš©: ~$0.02/ë§¤ì¥\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "collected_data = []\n",
    "collection_stats = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, shop in enumerate(BATCH_SHOPS, 1):\n",
    "    print(f\"\\n[{idx}/{len(BATCH_SHOPS)}] {shop['shop_name']} ({shop['category']})\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    shop_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # LLM ì§€ì‹ ê¸°ë°˜ ìˆ˜ì§‘ ì‹¤í–‰\n",
    "        result = auto_collect_shop_sources(\n",
    "            shop_seq=shop[\"shop_seq\"],\n",
    "            shop_name=shop[\"shop_name\"],\n",
    "            category=shop[\"category\"]\n",
    "        )\n",
    "        \n",
    "        shop_elapsed = time.time() - shop_start\n",
    "        \n",
    "        # í†µê³„\n",
    "        num_sources = len(result.get(\"sources\", []))\n",
    "        total_chars = sum(len(s[\"text\"]) for s in result.get(\"sources\", []))\n",
    "        \n",
    "        print(f\"\\nâœ… ì™„ë£Œ: {num_sources}/5ê°œ ì†ŒìŠ¤ ìˆ˜ì§‘ ({shop_elapsed:.1f}ì´ˆ)\")\n",
    "        print(f\"   - ì¹´í…Œê³ ë¦¬: {result.get('category')}\")\n",
    "        print(f\"   - ì´ í…ìŠ¤íŠ¸: {total_chars:,}ì\")\n",
    "        \n",
    "        collected_data.append(result)\n",
    "        collection_stats.append({\n",
    "            \"shop_name\": shop[\"shop_name\"],\n",
    "            \"category\": shop[\"category\"],\n",
    "            \"status\": \"success\",\n",
    "            \"num_sources\": num_sources,\n",
    "            \"total_chars\": total_chars,\n",
    "            \"elapsed_time\": shop_elapsed\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ì˜¤ë¥˜: {e}\")\n",
    "        collection_stats.append({\n",
    "            \"shop_name\": shop[\"shop_name\"],\n",
    "            \"category\": shop.get(\"category\", \"unknown\"),\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "    \n",
    "    # ë‹¤ìŒ ë§¤ì¥ê¹Œì§€ ëŒ€ê¸°\n",
    "    if idx < len(BATCH_SHOPS):\n",
    "        wait_seconds = 2\n",
    "        print(f\"\\nâ³ ë‹¤ìŒ ë§¤ì¥ê¹Œì§€ {wait_seconds}ì´ˆ ëŒ€ê¸°...\")\n",
    "        time.sleep(wait_seconds)\n",
    "\n",
    "total_elapsed = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nâœ… PHASE 1 ì™„ë£Œ: ì†ŒìŠ¤ ìƒì„± (ì´ {total_elapsed:.1f}ì´ˆ = {total_elapsed/60:.1f}ë¶„)\\n\")\n",
    "\n",
    "# í†µê³„\n",
    "success_count = sum(1 for s in collection_stats if s.get(\"status\") == \"success\")\n",
    "total_sources = sum(s.get(\"num_sources\", 0) for s in collection_stats)\n",
    "\n",
    "print(f\"ğŸ“Š í†µê³„:\")\n",
    "print(f\"   - ì„±ê³µ: {success_count}/{len(BATCH_SHOPS)}ê°œ ë§¤ì¥\")\n",
    "print(f\"   - ì´ ì†ŒìŠ¤: {total_sources}ê°œ (í‰ê·  {total_sources/success_count if success_count > 0 else 0:.1f}ê°œ/ë§¤ì¥)\")\n",
    "print(f\"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_elapsed / len(BATCH_SHOPS):.1f}ì´ˆ/ë§¤ì¥\")\n",
    "\n",
    "# ë¹„ìš© ê³„ì‚°\n",
    "llm_tokens_estimate = total_sources * 2000  # ì†ŒìŠ¤ë‹¹ ì•½ 2K tokens\n",
    "cost_estimate = (llm_tokens_estimate / 1000000) * 1.25  # Input token cost for Gemini 2.5 Pro\n",
    "print(f\"\\nğŸ’° ì˜ˆìƒ ë¹„ìš©:\")\n",
    "print(f\"   - LLM í† í°: ì•½ ${cost_estimate:.3f}\")\n",
    "print(f\"   - **ì´ ë¹„ìš©: ì•½ ${cost_estimate:.3f}** (ë§¤ì¥ë‹¹ ${cost_estimate/success_count if success_count > 0 else 0:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„: PHASE 2 - ë°ì´í„° ê²€ì¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# âœ… PHASE 2: ë°ì´í„° ê²€ì¦ (Validator)\n",
    "\n",
    "ìƒì„±ëœ ì†ŒìŠ¤ ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 7: ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë°ì´í„° ìŠ¤í‚¤ë§ˆ\n",
    "# ========================================\n",
    "\n",
    "VALID_SOURCE_TYPES = [\n",
    "    # fine_dining ì†ŒìŠ¤\n",
    "    \"michelin_review\",\n",
    "    \"blueribbon_review\",\n",
    "    \"chef_interview\",\n",
    "    \"course_description\",\n",
    "    \"brand_philosophy\",\n",
    "    # waiting_hotplace ì†ŒìŠ¤\n",
    "    \"signature_menu\",\n",
    "    \"atmosphere\",\n",
    "    \"popularity\",\n",
    "    \"price_value\",\n",
    "    \"location_access\",\n",
    "    # low_to_mid_price_dining ì†ŒìŠ¤\n",
    "    \"menu_composition\",\n",
    "    \"value_proposition\",\n",
    "    \"dining_atmosphere\",\n",
    "    \"reservation_parking\",\n",
    "    \"chef_approach\",\n",
    "    # ë ˆê±°ì‹œ (ì´ì „ ë²„ì „ í˜¸í™˜)\n",
    "    \"space_ambiance\",\n",
    "    \"tradition_technique\"\n",
    "]\n",
    "\n",
    "VALID_CATEGORIES = [\n",
    "    \"fine_dining\",\n",
    "    \"mid_price\",\n",
    "    \"waiting_hotplace\"\n",
    "]\n",
    "\n",
    "def validate_source_data(data: Dict) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    ì†ŒìŠ¤ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦\n",
    "    \n",
    "    Returns:\n",
    "        (is_valid, error_message)\n",
    "    \"\"\"\n",
    "    # í•„ìˆ˜ í•„ë“œ í™•ì¸\n",
    "    required_fields = [\"shop_seq\", \"shop_name\", \"category\", \"sources\"]\n",
    "    for field in required_fields:\n",
    "        if field not in data:\n",
    "            return False, f\"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}\"\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ í™•ì¸\n",
    "    if data[\"category\"] not in VALID_CATEGORIES:\n",
    "        return False, f\"ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬: {data['category']}\"\n",
    "    \n",
    "    # sources ë¦¬ìŠ¤íŠ¸ í™•ì¸\n",
    "    if not isinstance(data[\"sources\"], list):\n",
    "        return False, \"sourcesëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤\"\n",
    "    \n",
    "    if len(data[\"sources\"]) == 0:\n",
    "        return False, \"ìµœì†Œ 1ê°œ ì´ìƒì˜ ì†ŒìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤\"\n",
    "    \n",
    "    # ê° ì†ŒìŠ¤ ê²€ì¦\n",
    "    for idx, source in enumerate(data[\"sources\"]):\n",
    "        # í•„ìˆ˜ í•„ë“œ\n",
    "        source_required = [\"source_type\", \"text\"]\n",
    "        for field in source_required:\n",
    "            if field not in source:\n",
    "                return False, f\"ì†ŒìŠ¤ {idx}ë²ˆ: í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}\"\n",
    "        \n",
    "        # source_type í™•ì¸\n",
    "        if source[\"source_type\"] not in VALID_SOURCE_TYPES:\n",
    "            return False, f\"ì†ŒìŠ¤ {idx}ë²ˆ: ìœ íš¨í•˜ì§€ ì•Šì€ source_type: {source['source_type']}\"\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸\n",
    "        if len(source[\"text\"].strip()) < 50:\n",
    "            return False, f\"ì†ŒìŠ¤ {idx}ë²ˆ: í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ìµœì†Œ 50ì)\"\n",
    "    \n",
    "    return True, \"ê²€ì¦ í†µê³¼\"\n",
    "\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"   - ìœ íš¨í•œ ì†ŒìŠ¤ íƒ€ì…: {len(VALID_SOURCE_TYPES)}ê°€ì§€\")\n",
    "print(f\"   - ìœ íš¨í•œ ì¹´í…Œê³ ë¦¬: {', '.join(VALID_CATEGORIES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 8: ë°ì´í„° ê²€ì¦ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë°ì´í„° ê²€ì¦\n",
    "# ========================================\n",
    "\n",
    "print(\"ğŸ” ë°ì´í„° ê²€ì¦ ì¤‘...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "validation_results = []\n",
    "all_valid = True\n",
    "\n",
    "for idx, shop_data in enumerate(collected_data, 1):\n",
    "    shop_name = shop_data.get(\"shop_name\", f\"ë§¤ì¥{idx}\")\n",
    "    \n",
    "    print(f\"\\n[{idx}] {shop_name}\")\n",
    "    print(\"â”€\" * 80)\n",
    "    \n",
    "    is_valid, message = validate_source_data(shop_data)\n",
    "    \n",
    "    if is_valid:\n",
    "        print(f\"âœ… {message}\")\n",
    "        \n",
    "        # ìƒì„¸ ì •ë³´\n",
    "        num_sources = len(shop_data[\"sources\"])\n",
    "        total_chars = sum(len(s[\"text\"]) for s in shop_data[\"sources\"])\n",
    "        source_types = [s[\"source_type\"] for s in shop_data[\"sources\"]]\n",
    "        \n",
    "        print(f\"   - ì¹´í…Œê³ ë¦¬: {shop_data['category']}\")\n",
    "        print(f\"   - ì†ŒìŠ¤ ê°œìˆ˜: {num_sources}ê°œ\")\n",
    "        print(f\"   - ì´ í…ìŠ¤íŠ¸: {total_chars:,}ì\")\n",
    "        print(f\"   - ì†ŒìŠ¤ íƒ€ì…: {', '.join(source_types)}\")\n",
    "        \n",
    "        validation_results.append({\n",
    "            \"shop_name\": shop_name,\n",
    "            \"valid\": True,\n",
    "            \"num_sources\": num_sources,\n",
    "            \"total_chars\": total_chars\n",
    "        })\n",
    "    else:\n",
    "        print(f\"âŒ {message}\")\n",
    "        all_valid = False\n",
    "        \n",
    "        validation_results.append({\n",
    "            \"shop_name\": shop_name,\n",
    "            \"valid\": False,\n",
    "            \"error\": message\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "if all_valid:\n",
    "    print(\"\\nâœ… PHASE 2 ì™„ë£Œ: ëª¨ë“  ë°ì´í„° ê²€ì¦ í†µê³¼\")\n",
    "    print(f\"   - ì´ {len(collected_data)}ê°œ ë§¤ì¥\")\n",
    "    print(f\"   - ì´ {sum(r['num_sources'] for r in validation_results)}ê°œ ì†ŒìŠ¤\")\n",
    "    print(f\"   - ì´ {sum(r['total_chars'] for r in validation_results):,}ì\")\n",
    "else:\n",
    "    print(\"\\nâŒ PHASE 2 ì‹¤íŒ¨: ì¼ë¶€ ë°ì´í„°ì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ìœ„ì˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„: PHASE 3 - ë²¡í„° DB ì¸ë±ì‹±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ—„ï¸ PHASE 3: ë²¡í„° DB ì¸ë±ì‹± (Indexer)\n",
    "\n",
    "ê²€ì¦ëœ ì†ŒìŠ¤ ë°ì´í„°ë¥¼ ì²­í‚¹í•˜ê³  ë²¡í„° DBì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 8-A: Chroma DB ì™„ì „ ì‚­ì œ (ì„ íƒ)\n",
    "\n",
    "âš ï¸ **ì£¼ì˜**: ê¸°ì¡´ ë²¡í„° DBë¥¼ ì™„ì „íˆ ì‚­ì œí•˜ê³  ì‹¶ì„ ë•Œë§Œ ì‹¤í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "- ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•˜ë©´ `../chroma_db` ë””ë ‰í† ë¦¬ ì „ì²´ê°€ ì‚­ì œë©ë‹ˆë‹¤.\n",
    "- ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ë°ì´í„°ê°€ ì‚¬ë¼ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# âš ï¸ ì£¼ì˜: ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ë©´ DB ì „ì²´ ì‚­ì œ!\n",
    "# ========================================\n",
    "# import shutil\n",
    "\n",
    "# CHROMA_DB_PATH = \"../chroma_db\"\n",
    "\n",
    "# shutil.rmtree(CHROMA_DB_PATH)\n",
    "# print(\"\\nâœ… Chroma DB ì‚­ì œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 9: Chroma ë²¡í„° DB ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Chroma ë²¡í„° DB ì´ˆê¸°í™”\n",
    "# ========================================\n",
    "\n",
    "try:\n",
    "    chroma_client = chromadb.PersistentClient(path=\"../chroma_db\")\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ë³„ ì†ŒìŠ¤ ì»¬ë ‰ì…˜ ìƒì„± (ê¸°ì¡´ example ì»¬ë ‰ì…˜ê³¼ ë¶„ë¦¬)\n",
    "    fine_dining_sources = chroma_client.get_or_create_collection(\n",
    "        name=\"fine_dining_sources\",\n",
    "        metadata={\"hnsw:space\": \"cosine\", \"description\": \"íŒŒì¸ë‹¤ì´ë‹ ì›ë³¸ ì†ŒìŠ¤\"}\n",
    "    )\n",
    "    \n",
    "    low_to_mid_price_dining_sources = chroma_client.get_or_create_collection(\n",
    "        name=\"low_to_mid_price_dining_sources\",\n",
    "        metadata={\"hnsw:space\": \"cosine\", \"description\": \"ì¤‘ì €ê°€ ì›ë³¸ ì†ŒìŠ¤\"}\n",
    "    )\n",
    "    \n",
    "    waiting_hotplace_sources = chroma_client.get_or_create_collection(\n",
    "        name=\"waiting_hotplace_sources\",\n",
    "        metadata={\"hnsw:space\": \"cosine\", \"description\": \"ì›¨ì´íŒ… í•«í”Œ ì›ë³¸ ì†ŒìŠ¤\"}\n",
    "    )\n",
    "    \n",
    "    # ì»¬ë ‰ì…˜ ë§¤í•‘\n",
    "    SOURCE_COLLECTIONS = {\n",
    "        \"fine_dining\": fine_dining_sources,\n",
    "        \"mid_price\": low_to_mid_price_dining_sources,\n",
    "        \"waiting_hotplace\": waiting_hotplace_sources\n",
    "    }\n",
    "    \n",
    "    print(\"âœ… Chroma ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ (ê³µí†µ ë²¡í„° DB)\")\n",
    "    print(f\"   - ì €ì¥ ìœ„ì¹˜: ../chroma_db (shop_summary/chroma_db)\")\n",
    "    print(f\"\\n   ì¹´í…Œê³ ë¦¬ë³„ ì»¬ë ‰ì…˜:\")\n",
    "    for category, collection in SOURCE_COLLECTIONS.items():\n",
    "        print(f\"   - {category}_sources: {collection.count()}ê°œ ì²­í¬\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Chroma ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    chroma_client = None\n",
    "    SOURCE_COLLECTIONS = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 10: ì²­í‚¹ ë° ì„ë² ë”© í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ì²­í‚¹ ì„¤ì • (source_chunking_experiment.ipynb ê²°ê³¼ ê¸°ë°˜)\n",
    "# ========================================\n",
    "\n",
    "CHUNKING_CONFIG = {\n",
    "    # fine_dining ì†ŒìŠ¤\n",
    "    \"michelin_review\": {\n",
    "        \"method\": \"document\",\n",
    "        \"chunk_size\": None,\n",
    "        \"chunk_overlap\": 0\n",
    "    },\n",
    "    \"blueribbon_review\": {\n",
    "        \"method\": \"document\",\n",
    "        \"chunk_size\": None,\n",
    "        \"chunk_overlap\": 0\n",
    "    },\n",
    "    \"chef_interview\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 800,\n",
    "        \"chunk_overlap\": 200\n",
    "    },\n",
    "    \"course_description\": {\n",
    "        \"method\": \"semantic\",\n",
    "        \"chunk_size\": 512,\n",
    "        \"chunk_overlap\": 50\n",
    "    },\n",
    "    \"brand_philosophy\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 600,\n",
    "        \"chunk_overlap\": 100\n",
    "    },\n",
    "    \n",
    "    # waiting_hotplace ì†ŒìŠ¤\n",
    "    \"signature_menu\": {\n",
    "        \"method\": \"semantic\",\n",
    "        \"chunk_size\": 512,\n",
    "        \"chunk_overlap\": 50\n",
    "    },\n",
    "    \"atmosphere\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 600,\n",
    "        \"chunk_overlap\": 100\n",
    "    },\n",
    "    \"popularity\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 600,\n",
    "        \"chunk_overlap\": 100\n",
    "    },\n",
    "    \"price_value\": {\n",
    "        \"method\": \"document\",\n",
    "        \"chunk_size\": None,\n",
    "        \"chunk_overlap\": 0\n",
    "    },\n",
    "    \"location_access\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 512,\n",
    "        \"chunk_overlap\": 50\n",
    "    },\n",
    "    \n",
    "    # low_to_mid_price_dining ì†ŒìŠ¤\n",
    "    \"menu_composition\": {\n",
    "        \"method\": \"semantic\",\n",
    "        \"chunk_size\": 512,\n",
    "        \"chunk_overlap\": 50\n",
    "    },\n",
    "    \"value_proposition\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 600,\n",
    "        \"chunk_overlap\": 100\n",
    "    },\n",
    "    \"dining_atmosphere\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 600,\n",
    "        \"chunk_overlap\": 100\n",
    "    },\n",
    "    \"reservation_parking\": {\n",
    "        \"method\": \"document\",\n",
    "        \"chunk_size\": None,\n",
    "        \"chunk_overlap\": 0\n",
    "    },\n",
    "    \"chef_approach\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 800,\n",
    "        \"chunk_overlap\": 200\n",
    "    },\n",
    "    \n",
    "    # ë ˆê±°ì‹œ (ì´ì „ ë²„ì „ í˜¸í™˜)\n",
    "    \"space_ambiance\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 512,\n",
    "        \"chunk_overlap\": 50\n",
    "    },\n",
    "    \"tradition_technique\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 600,\n",
    "        \"chunk_overlap\": 100\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def chunk_text(text: str, source_type: str) -> List[str]:\n",
    "    \"\"\"ì†ŒìŠ¤ íƒ€ì…ì— ë§ëŠ” ì²­í‚¹ ì „ëµ ì ìš©\"\"\"\n",
    "    config = CHUNKING_CONFIG.get(source_type, CHUNKING_CONFIG[\"brand_philosophy\"])\n",
    "    \n",
    "    if config[\"method\"] == \"document\":\n",
    "        # ë¶„í•  ì—†ìŒ\n",
    "        return [text]\n",
    "    \n",
    "    elif config[\"method\"] == \"recursive\":\n",
    "        # LangChain RecursiveCharacterTextSplitter\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=config[\"chunk_size\"],\n",
    "            chunk_overlap=config[\"chunk_overlap\"],\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"],\n",
    "            length_function=len\n",
    "        )\n",
    "        return splitter.split_text(text)\n",
    "    \n",
    "    elif config[\"method\"] == \"semantic\":\n",
    "        # ê°„ë‹¨í•œ ë¬¸ì¥ ë‹¨ìœ„ ë¶„í• \n",
    "        sentences = text.replace(\". \", \".\\n\").replace(\"? \", \"?\\n\").replace(\"! \", \"!\\n\").split(\"\\n\")\n",
    "        \n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        current_length = 0\n",
    "        chunk_size = config[\"chunk_size\"]\n",
    "        chunk_overlap = config[\"chunk_overlap\"]\n",
    "        \n",
    "        for sent in sentences:\n",
    "            sent = sent.strip()\n",
    "            if not sent:\n",
    "                continue\n",
    "            \n",
    "            if current_length + len(sent) > chunk_size and current_chunk:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                \n",
    "                if chunk_overlap > 0 and current_chunk:\n",
    "                    overlap_text = current_chunk[-1]\n",
    "                    current_chunk = [overlap_text, sent]\n",
    "                    current_length = len(overlap_text) + len(sent)\n",
    "                else:\n",
    "                    current_chunk = [sent]\n",
    "                    current_length = len(sent)\n",
    "            else:\n",
    "                current_chunk.append(sent)\n",
    "                current_length += len(sent)\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    return [text]\n",
    "\n",
    "\n",
    "def generate_embedding(text: str, model=\"text-embedding-004\") -> List[float]:\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¥¼ 768ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ (google.genai SDK ì‚¬ìš©)\"\"\"\n",
    "    try:\n",
    "        response = client.models.embed_content(\n",
    "            model=model,\n",
    "            contents=text\n",
    "        )\n",
    "        return response.embeddings[0].values\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def index_source_data(shop_data: Dict, collection):\n",
    "    \"\"\"\n",
    "    í•œ ë§¤ì¥ì˜ ì†ŒìŠ¤ ë°ì´í„°ë¥¼ ì²­í‚¹í•˜ê³  ë²¡í„° DBì— ì €ì¥\n",
    "    \n",
    "    - ê°™ì€ ë§¤ì¥ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¨¼ì € ì‚­ì œ í›„ ì¬ìƒì„±\n",
    "    - ê³ ì•„ ì²­í¬ ë°©ì§€ë¥¼ ìœ„í•´ ë§¤ì¥ ë‹¨ìœ„ë¡œ ì™„ì „ ì‚­ì œ í›„ ì¬ìƒì„±\n",
    "    \n",
    "    Returns:\n",
    "        ì €ì¥ëœ ì²­í¬ ìˆ˜\n",
    "    \"\"\"\n",
    "    shop_seq = shop_data[\"shop_seq\"]\n",
    "    shop_name = shop_data[\"shop_name\"]\n",
    "    category = shop_data[\"category\"]\n",
    "    sources = shop_data[\"sources\"]\n",
    "    \n",
    "    # 1. ê¸°ì¡´ ë§¤ì¥ ë°ì´í„° ì‚­ì œ (ê³ ì•„ ì²­í¬ ë°©ì§€)\n",
    "    try:\n",
    "        existing = collection.get(\n",
    "            where={\"shop_seq\": shop_seq},\n",
    "            include=[]\n",
    "        )\n",
    "        if existing['ids']:\n",
    "            collection.delete(ids=existing['ids'])\n",
    "            print(f\"   ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ: {len(existing['ids'])}ê°œ ì²­í¬\")\n",
    "    except Exception as e:\n",
    "        # ì²« ì‹¤í–‰ ì‹œ ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìŒ\n",
    "        pass\n",
    "    \n",
    "    # 2. ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€\n",
    "    total_chunks_stored = 0\n",
    "    \n",
    "    for source_idx, source in enumerate(sources):\n",
    "        source_type = source[\"source_type\"]\n",
    "        text = source[\"text\"]\n",
    "        url = source.get(\"url\", \"\")\n",
    "        \n",
    "        # ì²­í‚¹\n",
    "        chunks = chunk_text(text, source_type)\n",
    "        \n",
    "        # ê° ì²­í¬ë¥¼ ë²¡í„° DBì— ì €ì¥\n",
    "        for chunk_idx, chunk in enumerate(chunks):\n",
    "            # ì„ë² ë”© ìƒì„±\n",
    "            embedding = generate_embedding(chunk)\n",
    "            \n",
    "            if embedding is None:\n",
    "                print(f\"   âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {shop_name} - {source_type} ì²­í¬ {chunk_idx}\")\n",
    "                continue\n",
    "            \n",
    "            # ê³ ìœ  ID ìƒì„±\n",
    "            doc_id = f\"{category}_{shop_seq}_{source_idx}_{chunk_idx}\"\n",
    "            \n",
    "            # Chromaì— ì €ì¥\n",
    "            collection.add(\n",
    "                documents=[chunk],\n",
    "                embeddings=[embedding],\n",
    "                metadatas=[{\n",
    "                    \"shop_seq\": shop_seq,\n",
    "                    \"shop_name\": shop_name,\n",
    "                    \"category\": category,\n",
    "                    \"source_type\": source_type,\n",
    "                    \"source_url\": url,\n",
    "                    \"chunk_index\": chunk_idx,\n",
    "                    \"total_chunks\": len(chunks),\n",
    "                    \"indexed_at\": datetime.utcnow().isoformat()\n",
    "                }],\n",
    "                ids=[doc_id]\n",
    "            )\n",
    "            \n",
    "            total_chunks_stored += 1\n",
    "            \n",
    "            # API Rate Limit ë°©ì§€\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    return total_chunks_stored\n",
    "\n",
    "\n",
    "print(\"âœ… ì²­í‚¹ ë° ì„ë² ë”© í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"   - chunk_text(): ì†ŒìŠ¤ íƒ€ì…ë³„ ì²­í‚¹\")\n",
    "print(f\"   - ì§€ì› ì†ŒìŠ¤ íƒ€ì…: {len(CHUNKING_CONFIG)}ê°€ì§€\")\n",
    "print(\"   - generate_embedding(): 768ì°¨ì› ì„ë² ë”© ìƒì„± (google.genai SDK)\")\n",
    "print(\"   - index_source_data(): ë²¡í„° DB ì¸ë±ì‹± (ë§¤ì¥ë³„ ì‚­ì œ í›„ ì¬ìƒì„±)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 11: ë²¡í„° DB ì¸ë±ì‹± ì‹¤í–‰\n",
    "\n",
    "âš ï¸ ì£¼ì˜: ì´ ì„¹ì…˜ì€ Vertex AI APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë²¡í„° DB ì¸ë±ì‹±\n",
    "# ========================================\n",
    "\n",
    "if not collected_data or not all_valid:\n",
    "    print(\"âš ï¸ ì¸ë±ì‹±í•  ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"ğŸš€ ë²¡í„° DB ì¸ë±ì‹± ì‹œì‘\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nì˜ˆìƒ ì‹œê°„: ì•½ {len(collected_data) * 2}ì´ˆ (ë§¤ì¥ë‹¹ ì•½ 2ì´ˆ)\\n\")\n",
    "    \n",
    "    indexing_results = []\n",
    "    indexing_start_time = time.time()\n",
    "    \n",
    "    for idx, shop_data in enumerate(collected_data, 1):\n",
    "        shop_name = shop_data[\"shop_name\"]\n",
    "        category = shop_data[\"category\"]\n",
    "        num_sources = len(shop_data[\"sources\"])\n",
    "        \n",
    "        print(f\"[{idx}/{len(collected_data)}] {shop_name} ({category})\")\n",
    "        print(f\"   ì†ŒìŠ¤ {num_sources}ê°œ ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ì»¬ë ‰ì…˜ ì„ íƒ\n",
    "        collection = SOURCE_COLLECTIONS.get(category)\n",
    "        \n",
    "        if not collection:\n",
    "            print(f\"   âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬: {category}\")\n",
    "            indexing_results.append({\n",
    "                \"shop_name\": shop_name,\n",
    "                \"category\": category,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"Invalid category\"\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # ì¸ë±ì‹± ì‹¤í–‰\n",
    "            shop_start = time.time()\n",
    "            chunks_stored = index_source_data(shop_data, collection)\n",
    "            shop_elapsed = time.time() - shop_start\n",
    "            \n",
    "            print(f\"   âœ… ì™„ë£Œ: {chunks_stored}ê°œ ì²­í¬ ì €ì¥ ({shop_elapsed:.1f}ì´ˆ)\\n\")\n",
    "            \n",
    "            indexing_results.append({\n",
    "                \"shop_name\": shop_name,\n",
    "                \"category\": category,\n",
    "                \"status\": \"success\",\n",
    "                \"chunks_stored\": chunks_stored,\n",
    "                \"elapsed_time\": shop_elapsed\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ì˜¤ë¥˜: {e}\\n\")\n",
    "            \n",
    "            indexing_results.append({\n",
    "                \"shop_name\": shop_name,\n",
    "                \"category\": category,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    indexing_elapsed = time.time() - indexing_start_time\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nâœ… PHASE 3 ì™„ë£Œ: ë²¡í„° DB ì¸ë±ì‹± (ì´ {indexing_elapsed:.1f}ì´ˆ)\\n\")\n",
    "    \n",
    "    # í†µê³„\n",
    "    success_count = sum(1 for r in indexing_results if r[\"status\"] == \"success\")\n",
    "    error_count = len(indexing_results) - success_count\n",
    "    total_chunks = sum(r.get(\"chunks_stored\", 0) for r in indexing_results)\n",
    "    \n",
    "    print(f\"ğŸ“Š í†µê³„:\")\n",
    "    print(f\"   - ì„±ê³µ: {success_count}ê°œ ë§¤ì¥\")\n",
    "    if error_count > 0:\n",
    "        print(f\"   - ì‹¤íŒ¨: {error_count}ê°œ ë§¤ì¥\")\n",
    "    print(f\"   - ì´ ì²­í¬: {total_chunks}ê°œ\")\n",
    "    print(f\"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {indexing_elapsed / len(collected_data):.1f}ì´ˆ/ë§¤ì¥\")\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ë³„ ì»¬ë ‰ì…˜ í¬ê¸°\n",
    "    print(f\"\\n   ì¹´í…Œê³ ë¦¬ë³„ ì»¬ë ‰ì…˜ í¬ê¸°:\")\n",
    "    for category, collection in SOURCE_COLLECTIONS.items():\n",
    "        print(f\"   - {category}_sources: {collection.count()}ê°œ ì²­í¬\")\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    df_results = pd.DataFrame(indexing_results)\n",
    "    csv_filename = f\"indexing_results_{timestamp}.csv\"\n",
    "    df_results.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\n",
    "\n",
    "3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 12: ì „ì²´ íŒŒì´í”„ë¼ì¸ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ì „ì²´ íŒŒì´í”„ë¼ì¸ ìš”ì•½\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ‰ í†µí•© ì†ŒìŠ¤ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“Š ì „ì²´ íŒŒì´í”„ë¼ì¸ ìš”ì•½:\\n\")\n",
    "\n",
    "# PHASE 1 ìš”ì•½\n",
    "if 'collection_stats' in globals():\n",
    "    phase1_success = sum(1 for s in collection_stats if s.get(\"status\") == \"success\")\n",
    "    phase1_sources = sum(s.get(\"num_sources\", 0) for s in collection_stats)\n",
    "    print(f\"âœ… PHASE 1: ì†ŒìŠ¤ ìƒì„±\")\n",
    "    print(f\"   - ì„±ê³µ: {phase1_success}/{len(BATCH_SHOPS)}ê°œ ë§¤ì¥\")\n",
    "    print(f\"   - ì´ ì†ŒìŠ¤: {phase1_sources}ê°œ\")\n",
    "    print(f\"   - ì†Œìš” ì‹œê°„: {total_elapsed:.1f}ì´ˆ\")\n",
    "    print()\n",
    "\n",
    "# PHASE 2 ìš”ì•½\n",
    "if 'validation_results' in globals():\n",
    "    phase2_valid = sum(1 for r in validation_results if r.get(\"valid\"))\n",
    "    print(f\"âœ… PHASE 2: ë°ì´í„° ê²€ì¦\")\n",
    "    print(f\"   - ê²€ì¦ í†µê³¼: {phase2_valid}/{len(validation_results)}ê°œ ë§¤ì¥\")\n",
    "    print()\n",
    "\n",
    "# PHASE 3 ìš”ì•½\n",
    "if 'indexing_results' in globals():\n",
    "    phase3_success = sum(1 for r in indexing_results if r.get(\"status\") == \"success\")\n",
    "    phase3_chunks = sum(r.get(\"chunks_stored\", 0) for r in indexing_results)\n",
    "    print(f\"âœ… PHASE 3: ë²¡í„° DB ì¸ë±ì‹±\")\n",
    "    print(f\"   - ì¸ë±ì‹± ì„±ê³µ: {phase3_success}/{len(indexing_results)}ê°œ ë§¤ì¥\")\n",
    "    print(f\"   - ì´ ì²­í¬: {phase3_chunks}ê°œ\")\n",
    "    print(f\"   - ì†Œìš” ì‹œê°„: {indexing_elapsed:.1f}ì´ˆ\")\n",
    "    print()\n",
    "\n",
    "# ì „ì²´ í†µê³„\n",
    "if 'total_elapsed' in globals() and 'indexing_elapsed' in globals():\n",
    "    total_pipeline_time = total_elapsed + indexing_elapsed\n",
    "    print(f\"â±ï¸ ì „ì²´ ì†Œìš” ì‹œê°„: {total_pipeline_time:.1f}ì´ˆ ({total_pipeline_time/60:.1f}ë¶„)\")\n",
    "    print()\n",
    "\n",
    "# ë¹„ìš© ìš”ì•½\n",
    "if 'cost_estimate' in globals():\n",
    "    print(f\"ğŸ’° ì˜ˆìƒ ë¹„ìš©: ${cost_estimate:.3f}\")\n",
    "    print()\n",
    "\n",
    "# ë²¡í„° DB ìƒíƒœ\n",
    "if SOURCE_COLLECTIONS:\n",
    "    print(f\"ğŸ—„ï¸ ë²¡í„° DB ìƒíƒœ:\")\n",
    "    for category, collection in SOURCE_COLLECTIONS.items():\n",
    "        print(f\"   - {category}_sources: {collection.count()}ê°œ ì²­í¬\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"   - main_rag_source.ipynb: ì›ë³¸ ì†ŒìŠ¤ ê¸°ë°˜ RAG ì‹¤í–‰\")\n",
    "print(\"   - main_rag_hybrid.ipynb: í•˜ì´ë¸Œë¦¬ë“œ RAG (ì›ë³¸ + ì˜ˆì‹œ) ì‹¤í–‰\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 13: ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ì„ íƒ)\n",
    "\n",
    "ì¸ë±ì‹±ëœ ë°ì´í„°ê°€ ì œëŒ€ë¡œ ê²€ìƒ‰ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "# ========================================\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\n",
    "TEST_QUERY = \"ì…°í”„ì˜ ì¡°ë¦¬ ì² í•™ê³¼ ì œì²  ì‹ì¬ë£Œ í™œìš© ë°©ë²•\"\n",
    "\n",
    "print(f\"ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\\n\")\n",
    "print(f\"ì¿¼ë¦¬: {TEST_QUERY}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±\n",
    "query_embedding = generate_embedding(TEST_QUERY)\n",
    "\n",
    "if query_embedding and SOURCE_COLLECTIONS:\n",
    "    # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê²€ìƒ‰\n",
    "    for category, collection in SOURCE_COLLECTIONS.items():\n",
    "        if collection.count() == 0:\n",
    "            print(f\"\\nğŸ“‚ {category}: ì €ì¥ëœ ì²­í¬ ì—†ìŒ\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nğŸ“‚ {category}\")\n",
    "        print(\"â”€\" * 80)\n",
    "        \n",
    "        try:\n",
    "            results = collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=min(3, collection.count()),\n",
    "                include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "            )\n",
    "            \n",
    "            if results['ids'] and len(results['ids'][0]) > 0:\n",
    "                for i in range(len(results['ids'][0])):\n",
    "                    metadata = results['metadatas'][0][i]\n",
    "                    document = results['documents'][0][i]\n",
    "                    distance = results['distances'][0][i]\n",
    "                    similarity = 1.0 - (distance / 2.0)\n",
    "                    \n",
    "                    print(f\"\\n   [{i+1}] {metadata['shop_name']} - {metadata['source_type']}\")\n",
    "                    print(f\"      ìœ ì‚¬ë„: {similarity:.3f}\")\n",
    "                    print(f\"      ì²­í¬: {metadata['chunk_index'] + 1}/{metadata['total_chunks']}\")\n",
    "                    \n",
    "                    preview = document[:150] + \"...\" if len(document) > 150 else document\n",
    "                    print(f\"      ë‚´ìš©: {preview}\")\n",
    "            else:\n",
    "                print(\"   ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "else:\n",
    "    print(\"âŒ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ì»¬ë ‰ì…˜ ì—†ìŒ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
