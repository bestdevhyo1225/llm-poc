{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2A: ì²­í‚¹ ì „ëµ ì‹¤í—˜ ë…¸íŠ¸ë¶\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì›ë³¸ ì†ŒìŠ¤ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²­í‚¹í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ì „ëµì„ ì‹¤í—˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©í‘œ\n",
    "1. ë°ì´í„° ì†ŒìŠ¤ë³„ ìµœì  ì²­í‚¹ ì „ëµ ë„ì¶œ\n",
    "2. Chunk Sizeì™€ Overlap íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "3. ê²€ìƒ‰ í’ˆì§ˆ ë¹„êµ (Relevance, Coverage)\n",
    "\n",
    "## ì‹¤í—˜ ëŒ€ìƒ ì†ŒìŠ¤\n",
    "- ë¯¸ì‰ë¦° ê°€ì´ë“œ ë¦¬ë·° (200-500ì)\n",
    "- ë¸”ë£¨ë¦¬ë³¸ ë¦¬ë·° (200-500ì)\n",
    "- ì…°í”„ ì¸í„°ë·° (1000-3000ì)\n",
    "- ì½”ìŠ¤ êµ¬ì„± ì„¤ëª… (300-800ì)\n",
    "- ë¸Œëœë“œ ì² í•™/ê³µê°„ (500-1000ì)\n",
    "\n",
    "## ì²­í‚¹ ë°©ë²•\n",
    "1. **Document ë°©ì‹**: ë¶„í•  ì—†ì´ ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ì²­í¬ë¡œ\n",
    "2. **Recursive ë°©ì‹**: ë¬¸ë‹¨ â†’ ë¬¸ì¥ ìˆœìœ¼ë¡œ ì¬ê·€ì  ë¶„í• \n",
    "3. **Semantic ë°©ì‹**: ì˜ë¯¸ ê¸°ë°˜ ë¶„í•  (spaCy)\n",
    "\n",
    "## ì‹¤í—˜ íŒŒë¼ë¯¸í„°\n",
    "- Chunk Size: 400, 512, 600, 800, 1200 (í† í°/ë¬¸ì ê¸°ì¤€)\n",
    "- Overlap: 0, 50, 100, 200, 300 (ë¬¸ì ê¸°ì¤€)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 1: íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ íŒ¨í‚¤ì§€ + ì²­í‚¹ìš© ì¶”ê°€ íŒ¨í‚¤ì§€\n",
    "%pip install google-cloud-aiplatform google-genai python-dotenv chromadb langchain langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 2: ë¼ì´ë¸ŒëŸ¬ë¦¬ Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vertexai\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from datetime import datetime\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import time\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ Import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 3: Vertex AI ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = \"wad-dw\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "print(f\"âœ… Vertex AI ì´ˆê¸°í™” ì™„ë£Œ: {PROJECT_ID} ({LOCATION})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 4: ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„\n",
    "\n",
    "ì‹¤ì œ ë§¤ì¥ ë°ì´í„°ë¥¼ ìƒ˜í”Œë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ë°ì´í„°: ë‹¤ì–‘í•œ ì†ŒìŠ¤ íƒ€ì…ë³„ í…ìŠ¤íŠ¸\n",
    "SAMPLE_DATA = {\n",
    "    \"michelin_review\": {\n",
    "        \"shop_name\": \"ëª¨ìˆ˜\",\n",
    "        \"text\": \"\"\"ëª¨ìˆ˜ëŠ” ì•ˆì„±ì¬ ì…°í”„ê°€ ìš´ì˜í•˜ëŠ” ëª¨ë˜ í•œì‹ ë ˆìŠ¤í† ë‘ì…ë‹ˆë‹¤. í™”ë• êµ¬ì´ ê¸°ë²•ì„ í™œìš©í•œ ì°½ì˜ì ì¸ í•œì‹ì„ ì„ ë³´ì´ë©°, ì œì²  ì‹ì¬ë£Œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œêµ­ì˜ ì „í†µ ì¡°ë¦¬ë²•ì— í˜„ëŒ€ì  ê°ê°ì„ ë”í–ˆìŠµë‹ˆë‹¤. ê¹”ë”í•˜ê³  ëª¨ë˜í•œ ê³µê°„ì—ì„œ ì…°í”„ì˜ ì² í•™ì´ ë‹´ê¸´ ì •êµí•œ í”Œë ˆì´íŒ…ì„ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¯¸ì‰ë¦° 2ìŠ¤íƒ€ë¥¼ ìœ ì§€í•˜ë©° í•œêµ­ íŒŒì¸ë‹¤ì´ë‹ì˜ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\"\",\n",
    "        \"category\": \"fine_dining\"\n",
    "    },\n",
    "    \"chef_interview\": {\n",
    "        \"shop_name\": \"ë°ê¸€ìŠ¤\",\n",
    "        \"text\": \"\"\"Q: ë°ê¸€ìŠ¤ì˜ ìš”ë¦¬ ì² í•™ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
    "A: ë°ê¸€ìŠ¤ëŠ” 'í•œêµ­ì˜ ë§›ì„ í˜„ëŒ€ì ìœ¼ë¡œ ì¬í•´ì„í•œë‹¤'ëŠ” ì² í•™ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ ì „í†µ ì‹ì¬ë£Œì™€ ë°œíš¨ ê¸°ë²•ì„ í™œìš©í•˜ë˜, ì„¸ê³„ì ì¸ ì¡°ë¦¬ ê¸°ë²•ê³¼ í”Œë ˆì´íŒ…ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì¥ë¥˜, ê¹€ì¹˜, ì “ê°ˆ ê°™ì€ í•œêµ­ ê³ ìœ ì˜ ë°œíš¨ ì‹í’ˆì„ ì†ŒìŠ¤ë‚˜ ì¡°ë¯¸ë£Œë¡œ í™œìš©í•˜ì—¬ ê¹Šì€ ê°ì¹ ë§›ì„ ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "Q: ê°€ì¥ ìë‘í•˜ëŠ” ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´ëŠ”?\n",
    "A: 'ì¥trio'ê°€ ëŒ€í‘œì ì…ë‹ˆë‹¤. ëœì¥, ê°„ì¥, ê³ ì¶”ì¥ì„ ê°ê° ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í™œìš©í•œ ì„¸ ê°€ì§€ ìš”ë¦¬ë¥¼ í•œ ì ‘ì‹œì— ë‹´ì•„ëƒ…ë‹ˆë‹¤. í•œêµ­ì¸ì—ê²Œ ìµìˆ™í•œ ì¥ë§›ì„ ì „í˜€ ìƒˆë¡œìš´ ë°©ì‹ìœ¼ë¡œ ê²½í—˜í•˜ê²Œ í•˜ì£ . ë˜í•œ 'ì§€ì§ì´ êµ¬ì´'ëŠ” ì „í†µ í•œì‹ì˜ ì§€ì§ì´ë¥¼ ê³ ê¸‰ ë‹¤ì´ë‹ ìŠ¤íƒ€ì¼ë¡œ ì¬í•´ì„í•œ ë©”ë‰´ë¡œ, í•´ì™¸ ì†ë‹˜ë“¤ì—ê²Œ íŠ¹íˆ ì¸ê¸°ê°€ ë§ìŠµë‹ˆë‹¤.\n",
    "\n",
    "Q: ì‹ì¬ë£Œ ì†Œì‹±ì€ ì–´ë–»ê²Œ í•˜ì‹œë‚˜ìš”?\n",
    "A: ë§¤ì¼ ì•„ì¹¨ ë…¸ëŸ‰ì§„ ìˆ˜ì‚°ì‹œì¥ê³¼ ê°€ë½ì‹œì¥ì— ì§ì ‘ ê°€ì„œ ì œì²  ì‹ì¬ë£Œë¥¼ ì„ ë³„í•©ë‹ˆë‹¤. íŠ¹íˆ ì§€ë°©ì˜ ì†Œê·œëª¨ ë†ê°€ì™€ ì§ê±°ë˜í•˜ë©° ìœ ê¸°ë† ì±„ì†Œë¥¼ ê³µê¸‰ë°›ê³  ìˆìŠµë‹ˆë‹¤. í•œìš°ëŠ” íš¡ì„±, í•´ì‚°ë¬¼ì€ ë‚¨í•´ì•ˆ ì–´ì´Œ, ìŒ€ì€ ì´ì²œì—ì„œ ì§ì ‘ ê³µìˆ˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "Q: ë°ê¸€ìŠ¤ë¥¼ ì°¾ëŠ” ê³ ê°ë“¤ì—ê²Œ ì „í•˜ê³  ì‹¶ì€ ë©”ì‹œì§€ëŠ”?\n",
    "A: ë°ê¸€ìŠ¤ëŠ” ë‹¨ìˆœíˆ ìŒì‹ì„ ë¨¹ëŠ” ê³³ì´ ì•„ë‹ˆë¼, í•œêµ­ ë¬¸í™”ë¥¼ ê²½í—˜í•˜ëŠ” ê³µê°„ì…ë‹ˆë‹¤. ê° ìš”ë¦¬ë§ˆë‹¤ í•œêµ­ì˜ ì—­ì‚¬ì™€ ì´ì•¼ê¸°ê°€ ë‹´ê²¨ ìˆê³ , ì €í¬ëŠ” ê·¸ê²ƒì„ í˜„ëŒ€ì  ì–¸ì–´ë¡œ ë²ˆì—­í•´ì„œ ì „ë‹¬í•©ë‹ˆë‹¤. í•œêµ­ì¸ì—ê²ŒëŠ” ìµìˆ™í•œ ë§›ì˜ ìƒˆë¡œìš´ ë°œê²¬ì„, ì™¸êµ­ì¸ì—ê²ŒëŠ” í•œêµ­ ë¯¸ì‹ì˜ ì§„ìˆ˜ë¥¼ ëŠë¼ì…¨ìœ¼ë©´ í•©ë‹ˆë‹¤.\"\"\",\n",
    "        \"category\": \"fine_dining\"\n",
    "    },\n",
    "    \"course_description\": {\n",
    "        \"shop_name\": \"ê¶Œìˆ™ìˆ˜\",\n",
    "        \"text\": \"\"\"ê¶Œìˆ™ìˆ˜ì˜ ì½”ìŠ¤ëŠ” í•œêµ­ì˜ ì‚¬ê³„ì ˆì„ ë‹´ì€ 12ê°€ì§€ ìš”ë¦¬ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. \n",
    "\n",
    "1. ì „ì±„: ì œì²  ì±„ì†Œë¥¼ í™œìš©í•œ ê³„ì ˆ ì „ì±„ 3ì¢… (ë´„ë‚˜ë¬¼, ì—¬ë¦„ ì—´ë§¤, ê°€ì„ ë²„ì„¯ ë“±)\n",
    "2. ì–´íŒ¨ë¥˜: ì œì£¼ì‚° ì „ë³µê³¼ ë‚¨í•´ì•ˆ í™œì–´ë¥¼ í™œìš©í•œ ìˆ™íšŒ ë˜ëŠ” ì°œ\n",
    "3. íƒ•: ì „í†µ ìœ¡ìˆ˜ë¥¼ ë² ì´ìŠ¤ë¡œ í•œ ë§‘ì€ íƒ• (ì†Œë¼ˆ ìš°ë¦° ìœ¡ìˆ˜, ë‹­ ìœ¡ìˆ˜ ë“±)\n",
    "4. êµ¬ì´: í•œìš° ë“±ì‹¬ ìˆ¯ë¶ˆ êµ¬ì´ ë˜ëŠ” ì œì²  ìƒì„  êµ¬ì´\n",
    "5. ì¡°ë¦¼: ì „í†µ ì¡°ë¦¼ ê¸°ë²•ì„ í™œìš©í•œ ë©”ì¸ ìš”ë¦¬\n",
    "6. ì‹ì‚¬: ëŒì†¥ë°¥ê³¼ ê¹€ì¹˜, ì¥ì•„ì°Œ, ëœì¥ì°Œê°œ\n",
    "7. í›„ì‹: ì „í†µ í•œê³¼ì™€ ì œì²  ê³¼ì¼\n",
    "\n",
    "ëª¨ë“  ì½”ìŠ¤ëŠ” ê¶Œìš°ì¤‘ ì…°í”„ê°€ ì§ì ‘ ì„ ë³„í•œ ì œì²  ì‹ì¬ë£Œë¡œ êµ¬ì„±ë˜ë©°, í•œêµ­ ì „í†µ ì¡°ë¦¬ë²•ì„ í˜„ëŒ€ì ìœ¼ë¡œ í•´ì„í•©ë‹ˆë‹¤.\"\"\",\n",
    "        \"category\": \"fine_dining\"\n",
    "    },\n",
    "    \"brand_philosophy\": {\n",
    "        \"shop_name\": \"ë‚˜ë² ë…¸ì´ì¦˜\",\n",
    "        \"text\": \"\"\"ë‚˜ë² ë…¸ì´ì¦˜ì€ 'ìŠ¤ì‹œì˜ ë³¸ì§ˆ'ì„ ì¶”êµ¬í•˜ëŠ” ì˜¤ë§ˆì¹´ì„¸ ë ˆìŠ¤í† ë‘ì…ë‹ˆë‹¤. ì´ì‹œì¹´ì™€ íˆë°ì•„í‚¤ ì…°í”„ëŠ” ë„ì¿„ì—ì„œ 15ë…„ê°„ ìŠ¤ì‹œ ì¥ì¸ìœ¼ë¡œ ìˆ˜ë ¨í•œ í›„, ì„œìš¸ì—ì„œ ì •í†µ ì—ë„ë§ˆì— ìŠ¤ì‹œë¥¼ ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìš°ë¦¬ì˜ ì² í•™ì€ ì„¸ ê°€ì§€ í•µì‹¬ ê°€ì¹˜ë¡œ ìš”ì•½ë©ë‹ˆë‹¤:\n",
    "\n",
    "1. ì‹ì¬ë£Œì˜ ë³¸ì§ˆ: ë§¤ì¼ ìƒˆë²½ ë…¸ëŸ‰ì§„ ìˆ˜ì‚°ì‹œì¥ê³¼ ì¼ë³¸ ì¸ í‚¤ì§€ ì‹œì¥ì—ì„œ ìµœê³  ë“±ê¸‰ì˜ ìˆ˜ì‚°ë¬¼ì„ ê³µìˆ˜í•©ë‹ˆë‹¤. ì œì²  ìƒì„ ë§Œì„ ì‚¬ìš©í•˜ë©°, ê° ì–´ì¢…ì˜ ìµœì  ìˆ™ì„± ê¸°ê°„ì„ ì§€ì¼œ ê°ì¹ ë§›ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. ì „í†µ ê¸°ë²•ì˜ ê³ ìˆ˜: ìƒ¤ë¦¬(ì´ˆë°¥ì˜ ë°¥)ëŠ” ì•„í‚¤íƒ€í˜„ ê³ ì‹œíˆì¹´ë¦¬ ìŒ€ì„ ì‚¬ìš©í•˜ë©°, ì ë¯¸ì´ˆë¥¼ ì§ì ‘ ë§Œë“¤ì–´ ê°„ì„ ë§ì¶¥ë‹ˆë‹¤. ë„¤íƒ€(ìŠ¤ì‹œ ì¬ë£Œ)ëŠ” ì „í†µ ì—ë„ë§ˆì— ë°©ì‹ìœ¼ë¡œ ì†ì§ˆí•˜ê³ , 100ë…„ ì „í†µì˜ ì¡°ë¦¼ ê¸°ë²•(ë‹ˆí‚¤ë¦¬, ì¸ ë©”)ì„ ê·¸ëŒ€ë¡œ ì¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "3. ì¥ì¸ì •ì‹ : í•˜ë£¨ ë‘ íƒ€ì„, ìµœëŒ€ 16ëª…ì˜ ì†ë‹˜ë§Œ ë°›ìœ¼ë©°, ì…°í”„ê°€ ì§ì ‘ í•œ ì  í•œ ì  ì¥ì–´ ë“œë¦½ë‹ˆë‹¤. ê³ ê°ê³¼ì˜ ëŒ€í™”ë¥¼ í†µí•´ ì·¨í–¥ì„ íŒŒì•…í•˜ê³ , ê·¸ì— ë§ì¶° ì½”ìŠ¤ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‚˜ë² ë…¸ì´ì¦˜ì˜ ê³µê°„ì€ ë¯¸ë‹ˆë©€í•˜ê³  ì ˆì œëœ ì¼ë³¸ì‹ ë¯¸í•™ì„ ì¶”êµ¬í•©ë‹ˆë‹¤. íˆë…¸í‚¤ ì›ëª© ì¹´ìš´í„°ì™€ ê³„ì ˆì„ ë‹´ì€ ì´ì¼€ë°”ë‚˜, ê·¸ë¦¬ê³  ì¡°ìš©íˆ íë¥´ëŠ” ì¬ì¦ˆ ìŒì•…ì´ ì–´ìš°ëŸ¬ì ¸ ìŠ¤ì‹œ ë³¸ì—°ì˜ ë§›ì— ì§‘ì¤‘í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.\"\"\",\n",
    "        \"category\": \"fine_dining\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"   - ë¯¸ì‰ë¦° ë¦¬ë·°: {len(SAMPLE_DATA['michelin_review']['text'])}ì\")\n",
    "print(f\"   - ì…°í”„ ì¸í„°ë·°: {len(SAMPLE_DATA['chef_interview']['text'])}ì\")\n",
    "print(f\"   - ì½”ìŠ¤ ì„¤ëª…: {len(SAMPLE_DATA['course_description']['text'])}ì\")\n",
    "print(f\"   - ë¸Œëœë“œ ì² í•™: {len(SAMPLE_DATA['brand_philosophy']['text'])}ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 5: ì²­í‚¹ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ì²­í‚¹ í•¨ìˆ˜\n",
    "# ========================================\n",
    "\n",
    "def chunk_document(text, method=\"document\", chunk_size=512, chunk_overlap=0):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ë¥¼ ì£¼ì–´ì§„ ë°©ì‹ìœ¼ë¡œ ì²­í‚¹í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text: ì›ë³¸ í…ìŠ¤íŠ¸\n",
    "        method: ì²­í‚¹ ë°©ì‹ (\"document\", \"recursive\", \"semantic\")\n",
    "        chunk_size: ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)\n",
    "        chunk_overlap: ì˜¤ë²„ë© í¬ê¸° (ë¬¸ì ìˆ˜)\n",
    "    \n",
    "    Returns:\n",
    "        ì²­í¬ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == \"document\":\n",
    "        # ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ì²­í¬ë¡œ\n",
    "        return [text]\n",
    "    \n",
    "    elif method == \"recursive\":\n",
    "        # LangChain RecursiveCharacterTextSplitter ì‚¬ìš©\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"],\n",
    "            length_function=len\n",
    "        )\n",
    "        return splitter.split_text(text)\n",
    "    \n",
    "    elif method == \"semantic\":\n",
    "        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ê°„ë‹¨í•œ êµ¬í˜„)\n",
    "        # ì‹¤ì œë¡œëŠ” spaCyë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ êµ¬í˜„\n",
    "        sentences = text.replace(\". \", \".\\n\").replace(\"? \", \"?\\n\").replace(\"! \", \"!\\n\").split(\"\\n\")\n",
    "        \n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        current_length = 0\n",
    "        \n",
    "        for sent in sentences:\n",
    "            sent = sent.strip()\n",
    "            if not sent:\n",
    "                continue\n",
    "            \n",
    "            if current_length + len(sent) > chunk_size and current_chunk:\n",
    "                # ì²­í¬ ì €ì¥\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                \n",
    "                # ì˜¤ë²„ë©: ë§ˆì§€ë§‰ ë¬¸ì¥ ìœ ì§€\n",
    "                if chunk_overlap > 0 and current_chunk:\n",
    "                    overlap_text = current_chunk[-1]\n",
    "                    current_chunk = [overlap_text, sent]\n",
    "                    current_length = len(overlap_text) + len(sent)\n",
    "                else:\n",
    "                    current_chunk = [sent]\n",
    "                    current_length = len(sent)\n",
    "            else:\n",
    "                current_chunk.append(sent)\n",
    "                current_length += len(sent)\n",
    "        \n",
    "        # ë§ˆì§€ë§‰ ì²­í¬\n",
    "        if current_chunk:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "\n",
    "def generate_embedding(text, model=\"text-embedding-004\"):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¥¼ 768ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜\"\"\"\n",
    "    try:\n",
    "        embedding_model = TextEmbeddingModel.from_pretrained(model)\n",
    "        embeddings = embedding_model.get_embeddings([text])\n",
    "        return embeddings[0].values\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def analyze_chunks(chunks, original_text):\n",
    "    \"\"\"\n",
    "    ì²­í¬ ë¶„ì„ í†µê³„\n",
    "    \"\"\"\n",
    "    chunk_lengths = [len(c) for c in chunks]\n",
    "    \n",
    "    return {\n",
    "        \"num_chunks\": len(chunks),\n",
    "        \"original_length\": len(original_text),\n",
    "        \"avg_chunk_length\": np.mean(chunk_lengths),\n",
    "        \"min_chunk_length\": np.min(chunk_lengths),\n",
    "        \"max_chunk_length\": np.max(chunk_lengths),\n",
    "        \"std_chunk_length\": np.std(chunk_lengths)\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… ì²­í‚¹ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"   - chunk_document(): í…ìŠ¤íŠ¸ë¥¼ ì²­í‚¹\")\n",
    "print(\"   - analyze_chunks(): ì²­í¬ í†µê³„ ë¶„ì„\")\n",
    "print(\"   - generate_embedding(): ì„ë² ë”© ìƒì„±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 6: ì²­í‚¹ ì „ëµ ë¹„êµ ì‹¤í—˜\n",
    "\n",
    "ë‹¤ì–‘í•œ ì†ŒìŠ¤ íƒ€ì…ì— ëŒ€í•´ ì—¬ëŸ¬ ì²­í‚¹ ì„¤ì •ì„ ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ì‹¤í—˜ ì„¤ì •\n",
    "# ========================================\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ì²­í‚¹ ì„¤ì •\n",
    "CHUNKING_CONFIGS = {\n",
    "    \"no_split\": {\n",
    "        \"method\": \"document\",\n",
    "        \"chunk_size\": None,\n",
    "        \"chunk_overlap\": 0,\n",
    "        \"description\": \"ë¶„í•  ì—†ìŒ (ì „ì²´ ë¬¸ì„œ)\"\n",
    "    },\n",
    "    \"small_no_overlap\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 400,\n",
    "        \"chunk_overlap\": 0,\n",
    "        \"description\": \"ì‘ì€ ì²­í¬, ì˜¤ë²„ë© ì—†ìŒ\"\n",
    "    },\n",
    "    \"medium_small_overlap\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 512,\n",
    "        \"chunk_overlap\": 50,\n",
    "        \"description\": \"ì¤‘ê°„ ì²­í¬, ì‘ì€ ì˜¤ë²„ë©\"\n",
    "    },\n",
    "    \"medium_medium_overlap\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 600,\n",
    "        \"chunk_overlap\": 100,\n",
    "        \"description\": \"ì¤‘ê°„ ì²­í¬, ì¤‘ê°„ ì˜¤ë²„ë©\"\n",
    "    },\n",
    "    \"large_large_overlap\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 800,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"description\": \"í° ì²­í¬, í° ì˜¤ë²„ë© (25%)\"\n",
    "    },\n",
    "    \"semantic_medium\": {\n",
    "        \"method\": \"semantic\",\n",
    "        \"chunk_size\": 512,\n",
    "        \"chunk_overlap\": 50,\n",
    "        \"description\": \"ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ì‹¤í—˜ ê²°ê³¼ ì €ì¥\n",
    "experiment_results = []\n",
    "\n",
    "print(\"ğŸ”¬ ì²­í‚¹ ì „ëµ ë¹„êµ ì‹¤í—˜ ì‹œì‘\\n\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# ê° ì†ŒìŠ¤ íƒ€ì…ë³„ë¡œ ì‹¤í—˜\n",
    "for source_type, source_data in SAMPLE_DATA.items():\n",
    "    text = source_data[\"text\"]\n",
    "    shop_name = source_data[\"shop_name\"]\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ì†ŒìŠ¤: {source_type} ({shop_name})\")\n",
    "    print(f\"   ì›ë³¸ ê¸¸ì´: {len(text)}ì\")\n",
    "    print(\"â”€\" * 100)\n",
    "    \n",
    "    # ê° ì²­í‚¹ ì„¤ì • í…ŒìŠ¤íŠ¸\n",
    "    for config_name, config in CHUNKING_CONFIGS.items():\n",
    "        print(f\"\\n   [{config_name}] {config['description']}\")\n",
    "        \n",
    "        # ì²­í‚¹ ì‹¤í–‰\n",
    "        chunks = chunk_document(\n",
    "            text=text,\n",
    "            method=config[\"method\"],\n",
    "            chunk_size=config.get(\"chunk_size\", 512),\n",
    "            chunk_overlap=config.get(\"chunk_overlap\", 0)\n",
    "        )\n",
    "        \n",
    "        # í†µê³„ ë¶„ì„\n",
    "        stats = analyze_chunks(chunks, text)\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        result = {\n",
    "            \"source_type\": source_type,\n",
    "            \"shop_name\": shop_name,\n",
    "            \"config_name\": config_name,\n",
    "            \"method\": config[\"method\"],\n",
    "            \"chunk_size\": config.get(\"chunk_size\"),\n",
    "            \"chunk_overlap\": config.get(\"chunk_overlap\"),\n",
    "            **stats\n",
    "        }\n",
    "        experiment_results.append(result)\n",
    "        \n",
    "        # ì¶œë ¥\n",
    "        print(f\"      ì²­í¬ ê°œìˆ˜: {stats['num_chunks']}ê°œ\")\n",
    "        print(f\"      í‰ê·  ê¸¸ì´: {stats['avg_chunk_length']:.1f}ì\")\n",
    "        print(f\"      ë²”ìœ„: {stats['min_chunk_length']:.0f} ~ {stats['max_chunk_length']:.0f}ì\")\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°\n",
    "        if chunks:\n",
    "            preview = chunks[0][:100] + \"...\" if len(chunks[0]) > 100 else chunks[0]\n",
    "            print(f\"      ë¯¸ë¦¬ë³´ê¸°: {preview}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(f\"\\nâœ… ì‹¤í—˜ ì™„ë£Œ: {len(experiment_results)}ê°œ ì„¤ì • í…ŒìŠ¤íŠ¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 7: ì‹¤í—˜ ê²°ê³¼ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df_results = pd.DataFrame(experiment_results)\n",
    "\n",
    "print(\"ğŸ“Š ì²­í‚¹ ì‹¤í—˜ ê²°ê³¼ ìš”ì•½\\n\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# ì†ŒìŠ¤ íƒ€ì…ë³„ ìš”ì•½\n",
    "for source_type in SAMPLE_DATA.keys():\n",
    "    print(f\"\\nğŸ“Œ {source_type}\")\n",
    "    print(\"â”€\" * 100)\n",
    "    \n",
    "    df_source = df_results[df_results['source_type'] == source_type]\n",
    "    \n",
    "    # í…Œì´ë¸” ì¶œë ¥\n",
    "    display_cols = ['config_name', 'num_chunks', 'avg_chunk_length', 'min_chunk_length', 'max_chunk_length']\n",
    "    print(df_source[display_cols].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "\n",
    "# CSV ì €ì¥\n",
    "csv_filename = f\"chunking_experiment_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "df_results.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 8: ê¶Œì¥ ì²­í‚¹ ì „ëµ\n",
    "\n",
    "ì‹¤í—˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì†ŒìŠ¤ íƒ€ì…ë³„ ìµœì  ì²­í‚¹ ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ê¶Œì¥ ì²­í‚¹ ì„¤ì •\n",
    "# ========================================\n",
    "\n",
    "RECOMMENDED_CHUNKING = {\n",
    "    \"michelin_review\": {\n",
    "        \"method\": \"document\",\n",
    "        \"chunk_size\": None,\n",
    "        \"chunk_overlap\": 0,\n",
    "        \"reason\": \"ì§§ê³  ì™„ê²°ëœ í…ìŠ¤íŠ¸ (200-500ì). ë¶„í•  ì‹œ ë§¥ë½ ì†ì‹¤ ìš°ë ¤.\"\n",
    "    },\n",
    "    \"blueribbon_review\": {\n",
    "        \"method\": \"document\",\n",
    "        \"chunk_size\": None,\n",
    "        \"chunk_overlap\": 0,\n",
    "        \"reason\": \"ë¯¸ì‰ë¦°ê³¼ ë™ì¼. ì§§ê³  ì™„ê²°ëœ ë¦¬ë·° ë‹¨ìœ„.\"\n",
    "    },\n",
    "    \"chef_interview\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 800,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"reason\": \"ê¸´ í…ìŠ¤íŠ¸ (1000-3000ì). Q&A ë§¥ë½ ìœ ì§€ë¥¼ ìœ„í•´ í° ì²­í¬ + 25% ì˜¤ë²„ë©.\"\n",
    "    },\n",
    "    \"course_description\": {\n",
    "        \"method\": \"semantic\",\n",
    "        \"chunk_size\": 512,\n",
    "        \"chunk_overlap\": 50,\n",
    "        \"reason\": \"ì¤‘ê°„ ê¸¸ì´ (300-800ì). ìš”ë¦¬ë³„ ì„¤ëª… ë‹¨ìœ„ë¡œ ë¶„í• .\"\n",
    "    },\n",
    "    \"brand_philosophy\": {\n",
    "        \"method\": \"recursive\",\n",
    "        \"chunk_size\": 600,\n",
    "        \"chunk_overlap\": 100,\n",
    "        \"reason\": \"ì¤‘ê°„~ê¸´ í…ìŠ¤íŠ¸ (500-1000ì). ì² í•™/ê³µê°„ ë§¥ë½ ìœ ì§€.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ’¡ ì†ŒìŠ¤ íƒ€ì…ë³„ ê¶Œì¥ ì²­í‚¹ ì „ëµ\\n\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for source_type, config in RECOMMENDED_CHUNKING.items():\n",
    "    print(f\"\\nğŸ“Œ {source_type}\")\n",
    "    print(\"â”€\" * 100)\n",
    "    print(f\"   ë°©ì‹: {config['method']}\")\n",
    "    print(f\"   ì²­í¬ í¬ê¸°: {config['chunk_size'] if config['chunk_size'] else 'N/A (ì „ì²´)'}\")\n",
    "    print(f\"   ì˜¤ë²„ë©: {config['chunk_overlap']}ì\")\n",
    "    print(f\"   ì´ìœ : {config['reason']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "\n",
    "# JSONìœ¼ë¡œ ì €ì¥\n",
    "config_filename = \"recommended_chunking_config.json\"\n",
    "with open(config_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(RECOMMENDED_CHUNKING, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nğŸ’¾ ì„¤ì • ì €ì¥: {config_filename}\")\n",
    "print(\"\\nâœ… ë‹¤ìŒ ë‹¨ê³„: ì´ ì„¤ì •ì„ source_indexer.ipynbì—ì„œ í™œìš©í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¹ì…˜ 9: ë²¡í„° DB ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ (ì„ íƒ)\n",
    "\n",
    "ì‹¤ì œë¡œ ì²­í‚¹ ì „ëµì´ ê²€ìƒ‰ í’ˆì§ˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ì‹œ Chroma ì»¬ë ‰ì…˜ ìƒì„± ë° ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ” ë²¡í„° DB ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ (ì„ íƒ ì‚¬í•­)\\n\")\n",
    "print(\"ì´ ì„¹ì…˜ì€ ì‹¤ì œ ê²€ìƒ‰ í’ˆì§ˆì„ ì¸¡ì •í•˜ê³  ì‹¶ì„ ë•Œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "print(\"ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì„ë² ë”© ìƒì„±).\")\n",
    "print(\"\\nâš ï¸ ì´ ì„¹ì…˜ì„ ê±´ë„ˆë›°ê³  ì‹¶ë‹¤ë©´ ë‹¤ìŒ ì…€ë¡œ ì´ë™í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ (ì˜µì…˜)\n",
    "# ì£¼ì˜: ì´ ì½”ë“œëŠ” ë§ì€ API í˜¸ì¶œì„ ë°œìƒì‹œí‚µë‹ˆë‹¤\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\n",
    "TEST_QUERIES = [\n",
    "    \"ì…°í”„ì˜ ì¡°ë¦¬ ì² í•™ê³¼ ì‹ì¬ë£Œ ì†Œì‹± ë°©ë²•\",\n",
    "    \"ì½”ìŠ¤ êµ¬ì„±ê³¼ ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´\",\n",
    "    \"ì „í†µ ê¸°ë²•ê³¼ í˜„ëŒ€ì  í•´ì„\"\n",
    "]\n",
    "\n",
    "# ì´ ë¶€ë¶„ì€ ì‹¤ì œë¡œ êµ¬í˜„í•˜ê³  ì‹¶ì„ ë•Œë§Œ ì‹¤í–‰\n",
    "# (ì„ë² ë”© ìƒì„± ë¹„ìš©ì´ ë°œìƒí•˜ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬)\n",
    "print(\"âš ï¸ ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ëŠ” í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "print(\"   í•„ìš” ì‹œ source_indexer.ipynbì—ì„œ êµ¬í˜„í•  ì˜ˆì •ì…ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê²°ë¡ \n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ ë‹¤ì–‘í•œ ì²­í‚¹ ì „ëµì„ ì‹¤í—˜í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "1. **Phase 2B**: `source_collector.ipynb` - ì‹¤ì œ ì›ë³¸ ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘\n",
    "2. **Phase 2C**: `source_indexer.ipynb` - ê¶Œì¥ ì„¤ì •ìœ¼ë¡œ ë²¡í„° DB ì¸ë±ì‹±\n",
    "3. **Phase 3**: `main_rag_source.ipynb` - Source-based RAG êµ¬í˜„\n",
    "4. **Phase 4**: `main_rag_hybrid.ipynb` - Hybrid RAG êµ¬í˜„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
