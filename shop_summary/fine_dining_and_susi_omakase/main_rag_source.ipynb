{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 4.0: íŒŒì¸ë‹¤ì´ë‹/ìŠ¤ì‹œì˜¤ë§ˆì¹´ì„¸ Source-based RAG ë²„ì „\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **ì›ë³¸ ì†ŒìŠ¤ ë°ì´í„°**ë¥¼ í™œìš©í•œ RAG ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“Œ í•µì‹¬ ì°¨ì´ì \n",
    "\n",
    "### ê¸°ì¡´ Example-based RAG (v3.0)\n",
    "- ê²€ìƒ‰ ëŒ€ìƒ: ê³¼ê±° ìƒì„±ëœ **ìš”ì•½ë¬¸ ì˜ˆì‹œ**\n",
    "- ëª©ì : ìš”ì•½ë¬¸ **ìŠ¤íƒ€ì¼** í•™ìŠµ\n",
    "- ë°ì´í„° ì–‘: ì ìŒ (ìš”ì•½ë¬¸ 180ì)\n",
    "\n",
    "### ìƒˆë¡œìš´ Source-based RAG (v4.0)\n",
    "- ê²€ìƒ‰ ëŒ€ìƒ: ë¯¸ì‰ë¦°/ë¸”ë£¨ë¦¬ë³¸/ì¸í„°ë·° ë“± **ì›ë³¸ ì†ŒìŠ¤**\n",
    "- ëª©ì : í’ë¶€í•œ **ë°°ê²½ ì§€ì‹** ì œê³µ\n",
    "- ë°ì´í„° ì–‘: ë§ìŒ (ì›ë³¸ í…ìŠ¤íŠ¸ ìˆ˜ë°±~ìˆ˜ì²œì)\n",
    "\n",
    "## ğŸ—„ï¸ ì‚¬ìš© ì»¬ë ‰ì…˜\n",
    "- `fine_dining_sources` â† ì›ë³¸ ì†ŒìŠ¤ ê²€ìƒ‰ (NEW)\n",
    "- `fine_dining_examples` â† ìƒì„± ì„±ê³µ ì‹œ ìš”ì•½ë¬¸ ì €ì¥ (ê¸°ì¡´ ìœ ì§€)\n",
    "\n",
    "## ğŸš€ ì‚¬ìš© ì „ ì¤€ë¹„ì‚¬í•­\n",
    "1. `knowledge_base/source_indexer.ipynb`ë¥¼ ì‹¤í–‰í•˜ì—¬ ì›ë³¸ ì†ŒìŠ¤ ì¸ë±ì‹± í•„ìš”\n",
    "2. `fine_dining_sources` ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ìˆì–´ì•¼ í•¨\n",
    "\n",
    "## ì˜ˆìƒ íš¨ê³¼\n",
    "- âœ… ë” í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ë¡œ í’ˆì§ˆ í–¥ìƒ\n",
    "- âœ… Cold Start ë¬¸ì œ í•´ê²° (ì²˜ìŒë¶€í„° ì›ë³¸ ì†ŒìŠ¤ í™œìš© ê°€ëŠ¥)\n",
    "- âœ… ë‹¤ì–‘í•œ í‘œí˜„ ê°€ëŠ¥ (ì˜ˆì‹œ ëª¨ë°© íƒˆí”¼)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš ï¸ ì„¹ì…˜ 1-4: ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¹ì…˜ 1: Package ì„¤ì¹˜\n",
    "%pip install google-cloud-aiplatform google-genai python-dotenv chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¹ì…˜ 2: ë¼ì´ë¸ŒëŸ¬ë¦¬ Import\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from datetime import datetime\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ Import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¹ì…˜ 3: Vertex AI ì´ˆê¸°í™”\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = \"wad-dw\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "print(f\"âœ… Vertex AI ì´ˆê¸°í™” ì™„ë£Œ: {PROJECT_ID} ({LOCATION})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¹ì…˜ 4: Chroma ë²¡í„° DB ì´ˆê¸°í™” (ê³µí†µ ë²¡í„° DB ì‚¬ìš©)\n",
    "try:\n",
    "    # ê³µí†µ ë²¡í„° DB ê²½ë¡œ: fine_dining_and_susi_omakase/../chroma_db = shop_summary/chroma_db\n",
    "    chroma_client = chromadb.PersistentClient(path=\"../chroma_db\")\n",
    "    \n",
    "    # ğŸ†• ì›ë³¸ ì†ŒìŠ¤ ì»¬ë ‰ì…˜ (ê²€ìƒ‰ìš©)\n",
    "    fine_dining_sources = chroma_client.get_or_create_collection(\n",
    "        name=\"fine_dining_sources\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    \n",
    "    # ê¸°ì¡´ ìš”ì•½ë¬¸ ì˜ˆì‹œ ì»¬ë ‰ì…˜ (ì €ì¥ìš©)\n",
    "    fine_dining_examples = chroma_client.get_or_create_collection(\n",
    "        name=\"fine_dining_examples\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Chroma ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ (ê³µí†µ ë²¡í„° DB)\")\n",
    "    print(f\"   - ì €ì¥ ìœ„ì¹˜: ../chroma_db (shop_summary/chroma_db)\")\n",
    "    print(f\"   - knowledge_base/source_indexer.ipynbì—ì„œ ìµœì´ˆ 1íšŒ ì¸ë±ì‹± í•„ìš”\\n\")\n",
    "    print(f\"   ğŸ“‚ ì›ë³¸ ì†ŒìŠ¤ (ê²€ìƒ‰ìš©):\")\n",
    "    print(f\"      - fine_dining_sources: {fine_dining_sources.count()}ê°œ ì²­í¬\")\n",
    "    print(f\"\\n   ğŸ“‚ ìš”ì•½ë¬¸ ì˜ˆì‹œ (ì €ì¥ìš©):\")\n",
    "    print(f\"      - fine_dining_examples: {fine_dining_examples.count()}ê°œ ìš”ì•½ë¬¸\")\n",
    "    \n",
    "    if fine_dining_sources.count() == 0:\n",
    "        print(\"\\n   âš ï¸ ê²½ê³ : fine_dining_sources ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"   knowledge_base/source_indexer.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ì›ë³¸ ì†ŒìŠ¤ë¥¼ ì¸ë±ì‹±í•˜ì„¸ìš”.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Chroma ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    chroma_client = None\n",
    "    fine_dining_sources = None\n",
    "    fine_dining_examples = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ì„¹ì…˜ 5: RAG í•¨ìˆ˜ ì •ì˜ (Source-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Source-based RAG í•¨ìˆ˜\n",
    "# ========================================\n",
    "\n",
    "def generate_embedding(text, model=\"text-embedding-004\"):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¥¼ 768ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜\"\"\"\n",
    "    try:\n",
    "        embedding_model = TextEmbeddingModel.from_pretrained(model)\n",
    "        embeddings = embedding_model.get_embeddings([text])\n",
    "        return embeddings[0].values\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def retrieve_similar_sources(query_text, collection, top_k=3):\n",
    "    \"\"\"\n",
    "    ë²¡í„° DBì—ì„œ ìœ ì‚¬í•œ ì›ë³¸ ì†ŒìŠ¤ ê²€ìƒ‰\n",
    "    \n",
    "    ì£¼ì˜: Example-basedì™€ ë‹¬ë¦¬ top_k=3 ê¶Œì¥ (ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸)\n",
    "    \"\"\"\n",
    "    if not collection:\n",
    "        print(\"âš ï¸ Chroma ì—°ê²° ì—†ìŒ - RAG ê±´ë„ˆë›°ê¸°\")\n",
    "        return []\n",
    "    \n",
    "    if collection.count() == 0:\n",
    "        print(\"âš ï¸ ì›ë³¸ ì†ŒìŠ¤ ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±\n",
    "        query_embedding = generate_embedding(query_text)\n",
    "        if not query_embedding:\n",
    "            return []\n",
    "        \n",
    "        # Chroma ë²¡í„° ê²€ìƒ‰\n",
    "        results = collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=min(top_k, collection.count()),\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "        )\n",
    "        \n",
    "        # Chroma ê²°ê³¼ í˜•ì‹ ë³€í™˜\n",
    "        formatted_results = []\n",
    "        \n",
    "        # resultsëŠ” ë°°ì¹˜ í˜•ì‹: {'ids': [[...]], 'documents': [[...]], ...}\n",
    "        if results['ids'] and len(results['ids'][0]) > 0:\n",
    "            for i in range(len(results['ids'][0])):\n",
    "                metadata = results['metadatas'][0][i]\n",
    "                distance = results['distances'][0][i]\n",
    "                document = results['documents'][0][i]\n",
    "                \n",
    "                # ì½”ì‚¬ì¸ ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (distance ë²”ìœ„: 0~2)\n",
    "                # distance 0 = ë™ì¼, distance 2 = ì •ë°˜ëŒ€\n",
    "                # similarity = 1 - (distance / 2)                \n",
    "                similarity = 1.0 - (distance / 2.0)\n",
    "                \n",
    "                formatted_results.append({\n",
    "                    \"shop_name\": metadata.get(\"shop_name\"),\n",
    "                    \"source_type\": metadata.get(\"source_type\"),\n",
    "                    \"text\": document,\n",
    "                    \"chunk_index\": metadata.get(\"chunk_index\", 0),\n",
    "                    \"score\": similarity\n",
    "                })\n",
    "        \n",
    "        return formatted_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def format_source_context(similar_sources):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ì›ë³¸ ì†ŒìŠ¤ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·\n",
    "    \"\"\"\n",
    "    if not similar_sources:\n",
    "        return \"[ì°¸ê³  ê°€ëŠ¥í•œ ì›ë³¸ ìë£Œ ì—†ìŒ]\"\n",
    "    \n",
    "    context = \"[ì°¸ê³  ìë£Œ - ì›ë³¸ ì†ŒìŠ¤]\\n\\n\"\n",
    "    \n",
    "    for idx, source in enumerate(similar_sources, 1):\n",
    "        shop_name = source.get('shop_name', 'Unknown')\n",
    "        source_type = source.get('source_type', 'unknown')\n",
    "        text = source.get('text', '')\n",
    "        score = source.get('score', 0)\n",
    "        \n",
    "        # ì†ŒìŠ¤ íƒ€ì… í•œê¸€ ë³€í™˜\n",
    "        type_mapping = {\n",
    "            \"michelin_review\": \"ë¯¸ì‰ë¦° ê°€ì´ë“œ\",\n",
    "            \"blueribbon_review\": \"ë¸”ë£¨ë¦¬ë³¸\",\n",
    "            \"chef_interview\": \"ì…°í”„ ì¸í„°ë·°\",\n",
    "            \"course_description\": \"ì½”ìŠ¤ ì„¤ëª…\",\n",
    "            \"brand_philosophy\": \"ë¸Œëœë“œ ì² í•™\",\n",
    "            \"space_ambiance\": \"ê³µê°„/ë¶„ìœ„ê¸°\",\n",
    "            \"tradition_technique\": \"ì „í†µ/ê¸°ë²•\"\n",
    "        }\n",
    "        type_kr = type_mapping.get(source_type, source_type)\n",
    "        \n",
    "        context += f\"**ì°¸ê³  ìë£Œ {idx}: {shop_name} - {type_kr}**\\n\"\n",
    "        context += f\"{text}\\n\"\n",
    "        context += f\"\\nìœ ì‚¬ë„: {score:.3f}\\n\"\n",
    "        context += \"â”€\" * 80 + \"\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "def store_successful_example(collection, shop_seq, shop_name, collected_info, \n",
    "                            title, summaries, category=\"fine_dining\"):\n",
    "    \"\"\"\n",
    "    ì„±ê³µí•œ ìš”ì•½ë¬¸ì„ examples ì»¬ë ‰ì…˜ì— ì €ì¥\n",
    "    (ê¸°ì¡´ Example-basedì™€ ë™ì¼)\n",
    "    \"\"\"\n",
    "    if not collection:\n",
    "        print(\"âš ï¸ Chroma ì—°ê²° ì—†ìŒ - ì €ì¥ ê±´ë„ˆë›°ê¸°\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        info_embedding = generate_embedding(collected_info)\n",
    "        \n",
    "        if not info_embedding:\n",
    "            print(\"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨\")\n",
    "            return False\n",
    "        \n",
    "        doc_id = f\"{category}_{shop_seq}_{datetime.utcnow().strftime('%Y%m%d%H%M%S')}\"\n",
    "        \n",
    "        collection.add(\n",
    "            documents=[collected_info],\n",
    "            embeddings=[info_embedding],\n",
    "            metadatas=[{\n",
    "                \"shop_seq\": shop_seq,\n",
    "                \"shop_name\": shop_name,\n",
    "                \"category\": category,\n",
    "                \"title\": title,\n",
    "                \"summaries\": json.dumps(summaries, ensure_ascii=False),\n",
    "                \"created_at\": datetime.utcnow().isoformat()\n",
    "            }],\n",
    "            ids=[doc_id]\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ: {shop_name}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "print(\"âœ… Source-based RAG í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"   - generate_embedding(): í…ìŠ¤íŠ¸ â†’ 768ì°¨ì› ë²¡í„°\")\n",
    "print(\"   - retrieve_similar_sources(): ì›ë³¸ ì†ŒìŠ¤ ê²€ìƒ‰ (NEW)\")\n",
    "print(\"   - format_source_context(): ì›ë³¸ ì†ŒìŠ¤ í¬ë§·íŒ… (NEW)\")\n",
    "print(\"   - store_successful_example(): ìš”ì•½ë¬¸ ì €ì¥ (ê¸°ì¡´)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ì„¹ì…˜ 6: ë§¤ì¥ ì •ë³´ ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë§¤ì¥ ì •ë³´ ì…ë ¥ (ë‹¤ì¤‘ ë§¤ì¥ ëª¨ë“œ)\n",
    "# ========================================\n",
    "\n",
    "# 1ï¸âƒ£ ë§¤ì¥ ê¸°ë³¸ ì •ë³´ (shop_seq, shop_name)\n",
    "SHOPS = [\n",
    "    (1, \"ëª¨ìˆ˜\"),\n",
    "    (2, \"ë°ê¸€ìŠ¤\"),\n",
    "    (3, \"ê°€ì˜¨\"),\n",
    "]\n",
    "\n",
    "# 2ï¸âƒ£ ë§¤ì¥ë³„ ìˆ˜ì§‘ëœ ì •ë³´ (ë§¤ì¥ëª…ì„ í‚¤ë¡œ ì‚¬ìš©)\n",
    "COLLECTED_INFO = {\n",
    "    \"ëª¨ìˆ˜\": \"\",\n",
    "    \"ë°ê¸€ìŠ¤\": \"\",\n",
    "    \"ê°€ì˜¨\": \"\",\n",
    "}\n",
    "\n",
    "# 3ï¸âƒ£ SHOP_LIST ìë™ ìƒì„± (shop_seq, shop_name, collected_info ë§¤í•‘)\n",
    "SHOP_LIST = [\n",
    "    {\n",
    "        \"shop_seq\": seq,\n",
    "        \"shop_name\": name,\n",
    "        \"collected_info\": COLLECTED_INFO.get(name, \"[ì •ë³´ ì—†ìŒ - COLLECTED_INFOì— ì¶”ê°€ í•„ìš”]\")\n",
    "    }\n",
    "    for seq, name in SHOPS\n",
    "]\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(f\"ğŸ“ ë‹¤ì¤‘ ë§¤ì¥ ëª¨ë“œ\")\n",
    "print(f\"   - ì´ ë§¤ì¥ ìˆ˜: {len(SHOP_LIST)}ê°œ\")\n",
    "for idx, shop in enumerate(SHOP_LIST, 1):\n",
    "    info_length = len(shop['collected_info'].strip())\n",
    "    status = \"âœ…\" if info_length > 100 else \"âš ï¸\"\n",
    "    print(f\"   {status} {idx}. {shop['shop_name']} (seq: {shop['shop_seq']}) - {info_length:,}ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ì„¹ì…˜ 7: ì •ë³´ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ ì„¹ì…˜ì€ ê±´ë„ˆëœë‹ˆë‹¤.\n",
    "# ì„¹ì…˜ 6ì˜ COLLECTED_INFO ë”•ì…”ë„ˆë¦¬ì—ì„œ ì´ë¯¸ ì •ë³´ë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "print(\"âœ… ë‹¤ì¤‘ ë§¤ì¥ ëª¨ë“œ\")\n",
    "print(\"   ì„¹ì…˜ 6ì˜ COLLECTED_INFOì— ë§¤ì¥ë³„ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "print(\"   ì…ë ¥ ì™„ë£Œ í›„ ë°”ë¡œ ì„¹ì…˜ 8ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ì„¹ì…˜ 8: Source-based RAG ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Source-based RAG í”„ë¡¬í”„íŠ¸ ì‹¤í–‰\n",
    "# ========================================\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ ë¯¸ì‰ë¦° ê°€ì´ë“œì™€ ë¸”ë£¨ë¦¬ë²ˆ ìˆ˜ì¤€ì˜ íŒŒì¸ë‹¤ì´ë‹ ë ˆìŠ¤í† ë‘ ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.\n",
    "ì œê³µëœ ì›ë³¸ ìë£Œ(ë¯¸ì‰ë¦° ê°€ì´ë“œ, ë¸”ë£¨ë¦¬ë³¸, ì…°í”„ ì¸í„°ë·° ë“±)ë¥¼ ì°¸ê³ í•˜ì—¬\n",
    "ë§¤ì¥ì˜ ì •ì²´ì„±ì„ ì••ì¶•ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ìš”ì•½ë¬¸ì„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì‘ì„± ì›ì¹™\n",
    "1. ì‚¬ì‹¤ ê¸°ë°˜: ì›ë³¸ ìë£Œì˜ ì •ë³´ë§Œ ì‚¬ìš©\n",
    "2. êµ¬ì¡°í™”: ì œëª© 1ê°œ + ìš”ì•½ ë¬¸ì¥ 3ê°œ\n",
    "3. ê°„ê²°ì„±: ê° ë¬¸ì¥ ì•½ 40-60ì\n",
    "4. ì „ë¬¸ì„±: ë¯¸ì‹ ìš©ì–´ ì •í™•íˆ ì‚¬ìš©\n",
    "5. ê°ê´€ì„±: ê³¼ì¥ ê¸ˆì§€\n",
    "6. ì°½ì˜ì„±: ì›ë³¸ ìë£Œë¥¼ ì¬í•´ì„í•˜ì—¬ ìƒˆë¡œìš´ í‘œí˜„ìœ¼ë¡œ ì‘ì„±\n",
    "\n",
    "## ìš”ì•½ ë¬¸ì¥ êµ¬ì¡°\n",
    "- **1ë²ˆ ë¬¸ì¥**: ì…°í”„ ì² í•™ / ë¸Œëœë“œ ì •ì²´ì„± / ì¡°ë¦¬ ì² í•™\n",
    "- **2ë²ˆ ë¬¸ì¥**: ì½”ìŠ¤ êµ¬ì„± / ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´ / ì¡°ë¦¬ ê¸°ë²•\n",
    "- **3ë²ˆ ë¬¸ì¥**: ê³µê°„ íŠ¹ì§• / ë¶„ìœ„ê¸° / ë¯¸ì‹ ê²½í—˜\n",
    "\n",
    "## ì œëª© ì‘ì„± ê·œì¹™\n",
    "- í˜•ì‹: \"[ê³µê°„ íŠ¹ì§•] ì†, [ì‹œê·¸ë‹ˆì²˜ ìš”ì†Œ]ë¥¼ [ë™ì‚¬]í•˜ëŠ” [ì¥ë¥´]\"\n",
    "- ê¸¸ì´: 15-30ì\n",
    "\n",
    "## ì¶œë ¥ í˜•ì‹\n",
    "{{\n",
    "  \"shop_seq\": ìˆ«ì,\n",
    "  \"shop_name\": \"ë§¤ì¥ëª…\",\n",
    "  \"title\": \"ì œëª©\",\n",
    "  \"summaries\": [\"ë¬¸ì¥1\", \"ë¬¸ì¥2\", \"ë¬¸ì¥3\"]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "generation_config = types.GenerateContentConfig(\n",
    "    temperature=0.5,\n",
    "    max_output_tokens=4096,\n",
    "    response_mime_type=\"application/json\"\n",
    ")\n",
    "\n",
    "print(f\"ğŸ¤– ëª¨ë¸: {MODEL_NAME}\")\n",
    "print(f\"   - Temperature: 0.5\\n\")\n",
    "\n",
    "\n",
    "def generate_summary_with_source_rag(shop_seq, shop_name, collected_info):\n",
    "    \"\"\"\n",
    "    Source-based RAGë¥¼ í™œìš©í•œ ìš”ì•½ë¬¸ ìƒì„±\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ì›ë³¸ ì†ŒìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰\n",
    "    similar_sources = retrieve_similar_sources(\n",
    "        query_text=collected_info,\n",
    "        collection=fine_dining_sources,\n",
    "        top_k=3  # Example-basedë³´ë‹¤ ë§ì´ (ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸)\n",
    "    )\n",
    "    \n",
    "    # 2. ì›ë³¸ ì†ŒìŠ¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„±\n",
    "    source_context = format_source_context(similar_sources)\n",
    "    \n",
    "    # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    user_prompt = f\"\"\"\n",
    "    {source_context}\n",
    "\n",
    "    [ìƒì„±í•  ë§¤ì¥ ì •ë³´]\n",
    "    ë§¤ì¥ëª…: {shop_name}\n",
    "    Shop Seq: {shop_seq}\n",
    "\n",
    "    [ìˆ˜ì§‘ëœ ì •ë³´]\n",
    "    {collected_info}\n",
    "\n",
    "    ìœ„ ì°¸ê³  ìë£Œì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {shop_name} ë§¤ì¥ì˜ ìš”ì•½ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL_NAME,\n",
    "            contents=f\"{system_prompt}\\n\\n{user_prompt}\",\n",
    "            config=generation_config\n",
    "        )\n",
    "        \n",
    "        result_text = response.text\n",
    "        result_json = json.loads(result_text)\n",
    "        \n",
    "        usage_metadata = response.usage_metadata if hasattr(response, 'usage_metadata') else None\n",
    "        token_info = {}\n",
    "        if usage_metadata:\n",
    "            token_info = {\n",
    "                \"input_tokens\": usage_metadata.prompt_token_count,\n",
    "                \"output_tokens\": usage_metadata.candidates_token_count,\n",
    "                \"total_tokens\": usage_metadata.total_token_count\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"data\": result_json,\n",
    "            \"tokens\": token_info,\n",
    "            \"source_count\": len(similar_sources)\n",
    "        }\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_type\": \"JSONDecodeError\",\n",
    "            \"message\": str(e),\n",
    "            \"response\": response.text if 'response' in locals() else None,\n",
    "            \"tokens\": {},\n",
    "            \"source_count\": len(similar_sources)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_type\": type(e).__name__,\n",
    "            \"message\": str(e),\n",
    "            \"response\": response.text if 'response' in locals() else None,\n",
    "            \"tokens\": {},\n",
    "            \"source_count\": len(similar_sources)\n",
    "        }\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# ë‹¤ì¤‘ ë§¤ì¥ ì²˜ë¦¬\n",
    "# -----------------------------------------\n",
    "all_results = []\n",
    "total_input_tokens = 0\n",
    "total_output_tokens = 0\n",
    "total_tokens = 0\n",
    "\n",
    "print(f\"ğŸ“ {len(SHOP_LIST)}ê°œ ë§¤ì¥ Source-based RAG ì‹¤í–‰\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx, shop in enumerate(SHOP_LIST, 1):\n",
    "    shop_seq = shop[\"shop_seq\"]\n",
    "    shop_name = shop[\"shop_name\"]\n",
    "    collected_info = shop[\"collected_info\"]\n",
    "    \n",
    "    print(f\"\\n[{idx}/{len(SHOP_LIST)}] {shop_name} ì²˜ë¦¬ ì¤‘...\")\n",
    "    print(f\"   ğŸ” ì›ë³¸ ì†ŒìŠ¤ ê²€ìƒ‰ ì¤‘...\")\n",
    "    \n",
    "    result = generate_summary_with_source_rag(shop_seq, shop_name, collected_info)\n",
    "    \n",
    "    if result[\"status\"] == \"success\":\n",
    "        result_json = result[\"data\"]\n",
    "        all_results.append(result_json)\n",
    "        \n",
    "        # í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥ ë° ëˆ„ì \n",
    "        tokens = result.get(\"tokens\", {})\n",
    "        if tokens:\n",
    "            input_tokens = tokens.get('input_tokens', 0)\n",
    "            output_tokens = tokens.get('output_tokens', 0)\n",
    "            total_tokens_shop = tokens.get('total_tokens', 0)\n",
    "            \n",
    "            total_input_tokens += input_tokens\n",
    "            total_output_tokens += output_tokens\n",
    "            total_tokens += total_tokens_shop\n",
    "            \n",
    "            print(f\"   âœ… ì„±ê³µ | ì›ë³¸ ì†ŒìŠ¤: {result['source_count']}ê°œ | Input: {input_tokens:,} | Output: {output_tokens:,} | Total: {total_tokens_shop:,} tokens\")\n",
    "        else:\n",
    "            print(f\"   âœ… ì„±ê³µ | ì›ë³¸ ì†ŒìŠ¤: {result['source_count']}ê°œ\")\n",
    "    else:\n",
    "        print(f\"   âŒ ì‹¤íŒ¨: {result['error_type']} - {result['message']}\")\n",
    "        # ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ ê¸°ë¡\n",
    "        all_results.append({\n",
    "            \"shop_seq\": shop_seq,\n",
    "            \"shop_name\": shop_name,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": result['message']\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nâœ… ì „ì²´ ì™„ë£Œ: {len(all_results)}ê°œ ë§¤ì¥ ì²˜ë¦¬\")\n",
    "\n",
    "# ì„±ê³µ/ì‹¤íŒ¨ ê°œìˆ˜\n",
    "success_count = sum(1 for r in all_results if r.get(\"status\") != \"error\")\n",
    "error_count = len(all_results) - success_count\n",
    "print(f\"   - ì„±ê³µ: {success_count}ê°œ\")\n",
    "if error_count > 0:\n",
    "    print(f\"   - ì‹¤íŒ¨: {error_count}ê°œ\")\n",
    "\n",
    "# ì´ í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥\n",
    "if total_tokens > 0:\n",
    "    print(f\"\\nğŸ“Š ì´ í† í° ì‚¬ìš©ëŸ‰:\")\n",
    "    print(f\"   - Total Input:  {total_input_tokens:,} tokens\")\n",
    "    print(f\"   - Total Output: {total_output_tokens:,} tokens\")\n",
    "    print(f\"   - Total:        {total_tokens:,} tokens\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# ì „ì²´ ê²°ê³¼ ìƒì„¸ ì¶œë ¥\n",
    "# -----------------------------------------\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“‹ ì „ì²´ ê²°ê³¼ ìƒì„¸ë³´ê¸°\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx, result in enumerate(all_results, 1):\n",
    "    print(f\"\\n{'â”€' * 80}\")\n",
    "    print(f\"[{idx}] {result.get('shop_name')}\")\n",
    "    print(f\"{'â”€' * 80}\")\n",
    "    \n",
    "    if result.get(\"status\") != \"error\":\n",
    "        # ì„±ê³µí•œ ê²½ìš° - ì „ì²´ ë‚´ìš© ì¶œë ¥\n",
    "        print(f\"\\nğŸ“Œ ì œëª©:\")\n",
    "        print(f\"   {result.get('title')}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ ìš”ì•½ë¬¸:\")\n",
    "        summaries = result.get('summaries', [])\n",
    "        for i, summary in enumerate(summaries, 1):\n",
    "            print(f\"   {i}. {summary}\")\n",
    "        \n",
    "        print(f\"\\nâœ… ìƒíƒœ: ì„±ê³µ\")\n",
    "    else:\n",
    "        # ì‹¤íŒ¨í•œ ê²½ìš°\n",
    "        print(f\"\\nâŒ ìƒíƒœ: ì—ëŸ¬\")\n",
    "        print(f\"   ì˜¤ë¥˜ ë‚´ìš©: {result.get('error', 'N/A')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ì„¹ì…˜ 9-10: ê²€ì¦ ë° ì €ì¥ (ê¸°ì¡´ê³¼ ë™ì¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¹ì…˜ 9: ê²€ì¦ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)\n",
    "# ì„¹ì…˜ 10: ì €ì¥ (fine_dining_examples ì»¬ë ‰ì…˜ì— ì €ì¥)\n",
    "\n",
    "print(\"âœ… ê²€ì¦ ë° ì €ì¥ ì„¹ì…˜\")\n",
    "print(\"   ê¸°ì¡´ main_rag.ipynbì˜ ì„¹ì…˜ 9-10ê³¼ ë™ì¼í•˜ê²Œ êµ¬í˜„\")\n",
    "print(\"   (ì§€ë©´ ê´€ê³„ìƒ ìƒëµ - í•„ìš” ì‹œ ë³µì‚¬)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ì œ Source-based RAGë¥¼ í…ŒìŠ¤íŠ¸í–ˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "### ë‹¤ìŒ: Hybrid RAG\n",
    "- `main_rag_hybrid.ipynb`ì—ì„œ **ì›ë³¸ ì†ŒìŠ¤ + ìš”ì•½ë¬¸ ì˜ˆì‹œ** ë‘˜ ë‹¤ í™œìš©\n",
    "- ìµœìƒì˜ í’ˆì§ˆì„ ìœ„í•œ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
