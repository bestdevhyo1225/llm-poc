"""
Qdrant Hybrid Search (Dense + Sparse) ë¡œì»¬ í…ŒìŠ¤íŠ¸
"""

from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, SparseVectorParams, PointStruct, SparseVector
from sentence_transformers import SentenceTransformer
from rank_bm25 import BM25Okapi
import numpy as np

# ========================================
# 1. ì´ˆê¸°í™”
# ========================================

# ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ (384ì°¨ì›, ë¹ ë¦„)
model = SentenceTransformer('all-MiniLM-L6-v2')

# Qdrant ë©”ëª¨ë¦¬ ëª¨ë“œ (íŒŒì¼ ì ê¸ˆ ë¬¸ì œ ì—†ìŒ)
client = QdrantClient(":memory:")

# ========================================
# 2. ì»¬ë ‰ì…˜ ìƒì„± (í•µì‹¬: Named Vectors)
# ========================================

client.create_collection(
    collection_name="test",
    vectors_config={
        "dense": VectorParams(size=384, distance=Distance.COSINE)  # Named vector
    },
    sparse_vectors_config={
        "sparse": SparseVectorParams()  # Named sparse vector
    }
)

print("âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")

# ========================================
# 3. í…ŒìŠ¤íŠ¸ ë°ì´í„°
# ========================================

docs = [
    "ë¯¸ì‰ë¦° 3ìŠ¤íƒ€ í”„ë Œì¹˜ íŒŒì¸ë‹¤ì´ë‹, ê³„ì ˆ ì‹ì¬ë£Œë¥¼ í™œìš©í•œ ëª¨ë˜ í€´ì§„",
    "ë¸”ë£¨ë¦¬ë³¸ ì´íƒˆë¦¬ì•ˆ ë ˆìŠ¤í† ë‘, í™ˆë©”ì´ë“œ íŒŒìŠ¤íƒ€ì™€ ë¦¬ì¡°ë˜ ì „ë¬¸",
    "ê°•ë‚¨ ì›¨ì´íŒ… ë§›ì§‘, SNSì—ì„œ í™”ì œì¸ ì¸ê¸° ë¸ŒëŸ°ì¹˜ ì¹´í˜"
]

# ========================================
# 4. Dense + Sparse ë²¡í„° ìƒì„±
# ========================================

# Dense: Sentence Transformer
dense_embeddings = model.encode(docs)
print(f"âœ… Dense ì„ë² ë”© ìƒì„±: {dense_embeddings.shape}")

# Sparse: BM25
tokenized_docs = [doc.split() for doc in docs]
bm25 = BM25Okapi(tokenized_docs)
print(f"âœ… BM25 ì¸ë±ì‹± ì™„ë£Œ: {len(docs)}ê°œ ë¬¸ì„œ")

# ========================================
# 5. Qdrantì— ì‚½ì…
# ========================================

points = []
for idx, (doc, dense) in enumerate(zip(docs, dense_embeddings)):
    # BM25 ìŠ¤ì½”ì–´ ê³„ì‚°
    sparse_scores = bm25.get_scores(doc.split())
    sparse_idx = np.where(sparse_scores > 0)[0]

    points.append(PointStruct(
        id=idx,
        vector={
            "dense": dense.tolist(),  # Named vectorì™€ ë§¤ì¹­
            "sparse": SparseVector(
                indices=sparse_idx.tolist(),
                values=sparse_scores[sparse_idx].tolist()
            )
        },
        payload={"text": doc}
    ))

client.upsert(collection_name="test", points=points)
print(f"âœ… {len(points)}ê°œ í¬ì¸íŠ¸ ì‚½ì… ì™„ë£Œ")

# ========================================
# 6. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
# ========================================

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
query = "í”„ë Œì¹˜ ë ˆìŠ¤í† ë‘"
query_dense = model.encode(query)
query_tokenized = query.split()
query_sparse_scores = bm25.get_scores(query_tokenized)
query_sparse_idx = np.where(query_sparse_scores > 0)[0]

# Hybrid ê²€ìƒ‰
results = client.query_points(
    collection_name="test",
    query=query_dense.tolist(),
    using="dense",  # Dense ë²¡í„° ì‚¬ìš©
    limit=3
)

print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
print("=" * 60)

for result in results.points:
    print(f"Score: {result.score:.4f}")
    print(f"Text: {result.payload['text']}")
    print("-" * 60)

# ========================================
# 7. ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
# ========================================

collection_info = client.get_collection("test")
print(f"\nğŸ“Š ì»¬ë ‰ì…˜ ì •ë³´:")
print(f"  - ì´ ë²¡í„° ìˆ˜: {collection_info.points_count}")
print(f"  - Dense ë²¡í„° ì°¨ì›: {collection_info.config.params.vectors['dense'].size}")
print(f"  - Sparse ë²¡í„°: {collection_info.config.params.sparse_vectors is not None}")

print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
