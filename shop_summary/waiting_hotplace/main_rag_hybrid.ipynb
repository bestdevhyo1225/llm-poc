{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 5.0: ì›¨ì´íŒ… í•«í”Œë ˆì´ìŠ¤ Hybrid RAG ë²„ì „\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **ì›ë³¸ ì†ŒìŠ¤ + ìš”ì•½ë¬¸ ì˜ˆì‹œ**ë¥¼ ëª¨ë‘ í™œìš©í•˜ëŠ” Hybrid RAG ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“Œ 3ê°€ì§€ RAG ë°©ì‹ ë¹„êµ\n",
    "\n",
    "| ë°©ì‹ | ê²€ìƒ‰ ëŒ€ìƒ | ì¥ì  | ë‹¨ì  |\n",
    "|------|-----------|------|------|\n",
    "| **Example-based** (v3.0) | ìš”ì•½ë¬¸ ì˜ˆì‹œ | ì¼ê´€ëœ ìŠ¤íƒ€ì¼ | ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡± |\n",
    "| **Source-based** (v4.0) | ì›ë³¸ ì†ŒìŠ¤ | í’ë¶€í•œ ì •ë³´ | ìŠ¤íƒ€ì¼ ë¶ˆì•ˆì • |\n",
    "| **Hybrid** (v5.0) | ë‘˜ ë‹¤ | ìµœê³  í’ˆì§ˆ | í† í° ë¹„ìš© ì¦ê°€ |\n",
    "\n",
    "## ğŸ¯ Hybrid ì ‘ê·¼ì˜ ì´ì \n",
    "\n",
    "1. **ë°°ê²½ ì§€ì‹**: ì›ë³¸ ì†ŒìŠ¤ì—ì„œ í’ë¶€í•œ ì •ë³´ íšë“\n",
    "2. **ìŠ¤íƒ€ì¼ ì¼ê´€ì„±**: ìš”ì•½ë¬¸ ì˜ˆì‹œì—ì„œ í†¤ì•¤ë§¤ë„ˆ í•™ìŠµ\n",
    "3. **ìµœì  ê· í˜•**: ì •ë³´ì˜ ê¹Šì´ + í‘œí˜„ì˜ ì¼ê´€ì„±\n",
    "\n",
    "## ğŸ—„ï¸ ì‚¬ìš© ì»¬ë ‰ì…˜\n",
    "- `waiting_hotplace_sources` â† ì›ë³¸ ì†ŒìŠ¤ ê²€ìƒ‰ (ë°°ê²½ ì§€ì‹)\n",
    "- `waiting_hotplace_examples` â† ìš”ì•½ë¬¸ ì˜ˆì‹œ ê²€ìƒ‰ (ìŠ¤íƒ€ì¼) + ì €ì¥\n",
    "\n",
    "## âš™ï¸ ê²€ìƒ‰ ì „ëµ\n",
    "- ì›ë³¸ ì†ŒìŠ¤: `top_k=2` (í•µì‹¬ ì •ë³´ë§Œ)\n",
    "- ìš”ì•½ë¬¸ ì˜ˆì‹œ: `top_k=2` (ìŠ¤íƒ€ì¼ ì°¸ê³ )\n",
    "- ì´ 4ê°œ ë¬¸ì„œ í™œìš© â†’ í’ë¶€í•˜ë©´ì„œë„ ì§‘ì¤‘ëœ ì»¨í…ìŠ¤íŠ¸\n",
    "\n",
    "## ğŸš€ ì‚¬ìš© ì „ ì¤€ë¹„\n",
    "1. `knowledge_base/source_indexer.ipynb` ì‹¤í–‰ (ì›ë³¸ ì†ŒìŠ¤ ì¸ë±ì‹±)\n",
    "2. `main_rag.ipynb` ë˜ëŠ” `main_rag_source.ipynb` ì‹¤í–‰ (ìš”ì•½ë¬¸ ì˜ˆì‹œ ì¶•ì )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš ï¸ ì„¹ì…˜ 1-4: ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¹ì…˜ 1: Package ì„¤ì¹˜\n",
    "%pip install google-cloud-aiplatform google-genai python-dotenv chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¹ì…˜ 2: ë¼ì´ë¸ŒëŸ¬ë¦¬ Import\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from datetime import datetime\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ Import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¹ì…˜ 3: Vertex AI ì´ˆê¸°í™”\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = \"wad-dw\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "print(f\"âœ… Vertex AI ì´ˆê¸°í™” ì™„ë£Œ: {PROJECT_ID} ({LOCATION})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¹ì…˜ 4: Chroma ë²¡í„° DB ì´ˆê¸°í™” (Hybrid - ê³µí†µ ë²¡í„° DB)\n",
    "try:\n",
    "    # ê³µí†µ ë²¡í„° DB ê²½ë¡œ\n",
    "    chroma_client = chromadb.PersistentClient(path=\"../chroma_db\")\n",
    "    \n",
    "    # ì›ë³¸ ì†ŒìŠ¤ ì»¬ë ‰ì…˜ (ë°°ê²½ ì§€ì‹ìš©)\n",
    "    waiting_hotplace_sources = chroma_client.get_or_create_collection(\n",
    "        name=\"waiting_hotplace_sources\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    \n",
    "    # ìš”ì•½ë¬¸ ì˜ˆì‹œ ì»¬ë ‰ì…˜ (ìŠ¤íƒ€ì¼ ì°¸ê³  + ì €ì¥ìš©)\n",
    "    waiting_hotplace_examples = chroma_client.get_or_create_collection(\n",
    "        name=\"waiting_hotplace_examples\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Chroma ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ (Hybrid Mode - ê³µí†µ ë²¡í„° DB)\")\n",
    "    print(f\"   - ì €ì¥ ìœ„ì¹˜: ../chroma_db (shop_summary/chroma_db)\")\n",
    "    print(f\"   - knowledge_base/source_indexer.ipynbì—ì„œ ìµœì´ˆ 1íšŒ ì¸ë±ì‹± í•„ìš”\\n\")\n",
    "    print(f\"   ğŸ“‚ ì›ë³¸ ì†ŒìŠ¤ (ë°°ê²½ ì§€ì‹):\")\n",
    "    print(f\"      - waiting_hotplace_sources: {waiting_hotplace_sources.count()}ê°œ ì²­í¬\")\n",
    "    print(f\"\\n   ğŸ“‚ ìš”ì•½ë¬¸ ì˜ˆì‹œ (ìŠ¤íƒ€ì¼ ì°¸ê³ ):\")\n",
    "    print(f\"      - waiting_hotplace_examples: {waiting_hotplace_examples.count()}ê°œ ìš”ì•½ë¬¸\")\n",
    "    \n",
    "    # ê²½ê³ \n",
    "    if waiting_hotplace_sources.count() == 0:\n",
    "        print(\"\\n   âš ï¸ waiting_hotplace_sourcesê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. source_indexer.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "    if waiting_hotplace_examples.count() == 0:\n",
    "        print(\"\\n   âš ï¸ waiting_hotplace_examplesê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ìŠ¤íƒ€ì¼ ì°¸ê³ ê°€ ì—†ì´ ì›ë³¸ ì†ŒìŠ¤ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Chroma ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    chroma_client = None\n",
    "    waiting_hotplace_sources = None\n",
    "    waiting_hotplace_examples = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ì„¹ì…˜ 5: Hybrid RAG í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Hybrid RAG í•¨ìˆ˜\n",
    "# ========================================\n",
    "\n",
    "def generate_embedding(text, model=\"text-embedding-004\"):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¥¼ 768ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜\"\"\"\n",
    "    try:\n",
    "        embedding_model = TextEmbeddingModel.from_pretrained(model)\n",
    "        embeddings = embedding_model.get_embeddings([text])\n",
    "        return embeddings[0].values\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def retrieve_similar_sources(query_text, collection, top_k=2):\n",
    "    \"\"\"ì›ë³¸ ì†ŒìŠ¤ ê²€ìƒ‰\"\"\"\n",
    "    if not collection or collection.count() == 0:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±\n",
    "        query_embedding = generate_embedding(query_text)\n",
    "        if not query_embedding:\n",
    "            return []\n",
    "        \n",
    "        # Chroma ë²¡í„° ê²€ìƒ‰\n",
    "        results = collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=min(top_k, collection.count()),\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "        )\n",
    "        \n",
    "        # Chroma ê²°ê³¼ í˜•ì‹ ë³€í™˜\n",
    "        formatted_results = []\n",
    "\n",
    "        # resultsëŠ” ë°°ì¹˜ í˜•ì‹: {'ids': [[...]], 'documents': [[...]], ...}\n",
    "        if results['ids'] and len(results['ids'][0]) > 0:\n",
    "            for i in range(len(results['ids'][0])):\n",
    "                metadata = results['metadatas'][0][i]\n",
    "                distance = results['distances'][0][i]\n",
    "                document = results['documents'][0][i]\n",
    "\n",
    "                # ì½”ì‚¬ì¸ ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (distance ë²”ìœ„: 0~2)\n",
    "                # distance 0 = ë™ì¼, distance 2 = ì •ë°˜ëŒ€\n",
    "                # similarity = 1 - (distance / 2)                \n",
    "                similarity = 1.0 - (distance / 2.0)\n",
    "                \n",
    "                formatted_results.append({\n",
    "                    \"shop_name\": metadata.get(\"shop_name\"),\n",
    "                    \"source_type\": metadata.get(\"source_type\"),\n",
    "                    \"text\": document,\n",
    "                    \"score\": similarity\n",
    "                })\n",
    "        \n",
    "        return formatted_results\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì›ë³¸ ì†ŒìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def retrieve_similar_examples(query_text, collection, top_k=2):\n",
    "    \"\"\"ìš”ì•½ë¬¸ ì˜ˆì‹œ ê²€ìƒ‰\"\"\"\n",
    "    if not collection or collection.count() == 0:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        query_embedding = generate_embedding(query_text)\n",
    "        if not query_embedding:\n",
    "            return []\n",
    "        \n",
    "        results = collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=min(top_k, collection.count()),\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "        )\n",
    "        \n",
    "        formatted_results = []\n",
    "        if results['ids'] and len(results['ids'][0]) > 0:\n",
    "            for i in range(len(results['ids'][0])):\n",
    "                metadata = results['metadatas'][0][i]\n",
    "                distance = results['distances'][0][i]\n",
    "                similarity = 1.0 - (distance / 2.0)\n",
    "                \n",
    "                formatted_results.append({\n",
    "                    \"shop_name\": metadata.get(\"shop_name\"),\n",
    "                    \"title\": metadata.get(\"title\"),\n",
    "                    \"summaries\": json.loads(metadata.get(\"summaries\", \"[]\")),\n",
    "                    \"score\": similarity\n",
    "                })\n",
    "        \n",
    "        return formatted_results\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ìš”ì•½ë¬¸ ì˜ˆì‹œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def format_hybrid_context(sources, examples):\n",
    "    \"\"\"\n",
    "    ì›ë³¸ ì†ŒìŠ¤ + ìš”ì•½ë¬¸ ì˜ˆì‹œë¥¼ í•˜ì´ë¸Œë¦¬ë“œ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·\n",
    "    \"\"\"\n",
    "    context = \"\"\n",
    "    \n",
    "    # 1. ì›ë³¸ ì†ŒìŠ¤ ì„¹ì…˜\n",
    "    if sources:\n",
    "        context += \"[ì°¸ê³  ìë£Œ - ì›ë³¸ ì†ŒìŠ¤]\\n\\n\"\n",
    "        \n",
    "        type_mapping = {\n",
    "            \"michelin_review\": \"ë¯¸ì‰ë¦° ê°€ì´ë“œ\",\n",
    "            \"blueribbon_review\": \"ë¸”ë£¨ë¦¬ë³¸\",\n",
    "            \"chef_interview\": \"ì…°í”„ ì¸í„°ë·°\",\n",
    "            \"course_description\": \"ì½”ìŠ¤ ì„¤ëª…\",\n",
    "            \"brand_philosophy\": \"ë¸Œëœë“œ ì² í•™\",\n",
    "            \"space_ambiance\": \"ê³µê°„/ë¶„ìœ„ê¸°\",\n",
    "            \"tradition_technique\": \"ì „í†µ/ê¸°ë²•\"\n",
    "        }\n",
    "        \n",
    "        for idx, source in enumerate(sources, 1):\n",
    "            shop_name = source.get('shop_name', 'Unknown')\n",
    "            source_type = source.get('source_type', 'unknown')\n",
    "            type_kr = type_mapping.get(source_type, source_type)\n",
    "            text = source.get('text', '')\n",
    "            score = source.get('score', 0)\n",
    "            \n",
    "            context += f\"**ì›ë³¸ ìë£Œ {idx}: {shop_name} - {type_kr}**\\n\"\n",
    "            context += f\"{text}\\n\"\n",
    "            context += f\"ìœ ì‚¬ë„: {score:.3f}\\n\"\n",
    "            context += \"â”€\" * 80 + \"\\n\\n\"\n",
    "    else:\n",
    "        context += \"[ì›ë³¸ ì†ŒìŠ¤ ì—†ìŒ]\\n\\n\"\n",
    "    \n",
    "    # 2. ìš”ì•½ë¬¸ ì˜ˆì‹œ ì„¹ì…˜\n",
    "    if examples:\n",
    "        context += \"[ì‘ì„± ì˜ˆì‹œ - ìš”ì•½ë¬¸ ìŠ¤íƒ€ì¼ ì°¸ê³ ]\\n\\n\"\n",
    "        \n",
    "        for idx, example in enumerate(examples, 1):\n",
    "            shop_name = example.get('shop_name', 'Unknown')\n",
    "            title = example.get('title', '')\n",
    "            summaries = example.get('summaries', [])\n",
    "            score = example.get('score', 0)\n",
    "            \n",
    "            context += f\"**ì‘ì„± ì˜ˆì‹œ {idx}: {shop_name}**\\n\"\n",
    "            context += f\"ì œëª©: {title}\\n\"\n",
    "            context += f\"ìš”ì•½ë¬¸:\\n\"\n",
    "            for i, summary in enumerate(summaries, 1):\n",
    "                context += f\"  {i}. {summary}\\n\"\n",
    "            context += f\"ìœ ì‚¬ë„: {score:.3f}\\n\"\n",
    "            context += \"â”€\" * 80 + \"\\n\\n\"\n",
    "    else:\n",
    "        context += \"[ì‘ì„± ì˜ˆì‹œ ì—†ìŒ]\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "def store_successful_example(collection, shop_seq, shop_name, collected_info, \n",
    "                            title, summaries, category=\"waiting_hotplace\"):\n",
    "    \"\"\"ì„±ê³µí•œ ìš”ì•½ë¬¸ ì €ì¥\"\"\"\n",
    "    if not collection:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        info_embedding = generate_embedding(collected_info)\n",
    "        if not info_embedding:\n",
    "            return False\n",
    "        \n",
    "        doc_id = f\"{category}_{shop_seq}_{datetime.utcnow().strftime('%Y%m%d%H%M%S')}\"\n",
    "        \n",
    "        collection.add(\n",
    "            documents=[collected_info],\n",
    "            embeddings=[info_embedding],\n",
    "            metadatas=[{\n",
    "                \"shop_seq\": shop_seq,\n",
    "                \"shop_name\": shop_name,\n",
    "                \"category\": category,\n",
    "                \"title\": title,\n",
    "                \"summaries\": json.dumps(summaries, ensure_ascii=False),\n",
    "                \"created_at\": datetime.utcnow().isoformat()\n",
    "            }],\n",
    "            ids=[doc_id]\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ: {shop_name}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "print(\"âœ… Hybrid RAG í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"   - retrieve_similar_sources(): ì›ë³¸ ì†ŒìŠ¤ ê²€ìƒ‰\")\n",
    "print(\"   - retrieve_similar_examples(): ìš”ì•½ë¬¸ ì˜ˆì‹œ ê²€ìƒ‰\")\n",
    "print(\"   - format_hybrid_context(): í•˜ì´ë¸Œë¦¬ë“œ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (NEW)\")\n",
    "print(\"   - store_successful_example(): ìš”ì•½ë¬¸ ì €ì¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ì„¹ì…˜ 6-7: ë§¤ì¥ ì •ë³´ ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ë§¤ì¥ ì •ë³´ ì…ë ¥ (ë‹¤ì¤‘ ë§¤ì¥ ëª¨ë“œ)\n",
    "# ========================================\n",
    "\n",
    "# 1ï¸âƒ£ ë§¤ì¥ ê¸°ë³¸ ì •ë³´ (shop_seq, shop_name)\n",
    "SHOPS = [\n",
    "    (1, \"ì„±ìˆ˜ì—°ë°©\"),\n",
    "    (2, \"ë¥´ë°”ê²ŒíŠ¸\"),\n",
    "    (3, \"ë‹´ì†Œì‚¬ê³¨ìˆœëŒ€\"),\n",
    "]\n",
    "\n",
    "# 2ï¸âƒ£ ë§¤ì¥ë³„ ìˆ˜ì§‘ëœ ì •ë³´ (ë§¤ì¥ëª…ì„ í‚¤ë¡œ ì‚¬ìš©)\n",
    "COLLECTED_INFO = {\n",
    "    \"ì„±ìˆ˜ì—°ë°©\": \"\",\n",
    "    \"ë¥´ë°”ê²ŒíŠ¸\": \"\",\n",
    "    \"ë‹´ì†Œì‚¬ê³¨ìˆœëŒ€\": \"\",\n",
    "}\n",
    "\n",
    "# 3ï¸âƒ£ SHOP_LIST ìë™ ìƒì„± (shop_seq, shop_name, collected_info ë§¤í•‘)\n",
    "SHOP_LIST = [\n",
    "    {\n",
    "        \"shop_seq\": seq,\n",
    "        \"shop_name\": name,\n",
    "        \"collected_info\": COLLECTED_INFO.get(name, \"[ì •ë³´ ì—†ìŒ - COLLECTED_INFOì— ì¶”ê°€ í•„ìš”]\")\n",
    "    }\n",
    "    for seq, name in SHOPS\n",
    "]\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(f\"ğŸ“ ë‹¤ì¤‘ ë§¤ì¥ ëª¨ë“œ\")\n",
    "print(f\"   - ì´ ë§¤ì¥ ìˆ˜: {len(SHOP_LIST)}ê°œ\")\n",
    "for idx, shop in enumerate(SHOP_LIST, 1):\n",
    "    info_length = len(shop['collected_info'].strip())\n",
    "    status = \"âœ…\" if info_length > 100 else \"âš ï¸\"\n",
    "    print(f\"   {status} {idx}. {shop['shop_name']} (seq: {shop['shop_seq']}) - {info_length:,}ì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ ì„¹ì…˜ì€ ê±´ë„ˆëœë‹ˆë‹¤.\n",
    "# ì„¹ì…˜ 6ì˜ COLLECTED_INFO ë”•ì…”ë„ˆë¦¬ì—ì„œ ì´ë¯¸ ì •ë³´ë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "print(\"âœ… ë‹¤ì¤‘ ë§¤ì¥ ëª¨ë“œ\")\n",
    "print(\"   ì„¹ì…˜ 6ì˜ COLLECTED_INFOì— ë§¤ì¥ë³„ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "print(\"   ì…ë ¥ ì™„ë£Œ í›„ ë°”ë¡œ ì„¹ì…˜ 8ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ì„¹ì…˜ 8: Hybrid RAG ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Hybrid RAG í”„ë¡¬í”„íŠ¸ ì‹¤í–‰\n",
    "# ========================================\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ íŠ¸ë Œë””í•˜ê³  ëŒ€ì¤‘ì ì¸ ë§›ì§‘ ì†Œê°œ ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ì œê³µëœ ìë£Œ\n",
    "1. **ì›ë³¸ ìë£Œ**: ë¯¸ì‰ë¦° ê°€ì´ë“œ, ë¸”ë£¨ë¦¬ë³¸, ì…°í”„ ì¸í„°ë·° ë“± (ë°°ê²½ ì§€ì‹ ë° ì‚¬ì‹¤ ì •ë³´)\n",
    "2. **ì‘ì„± ì˜ˆì‹œ**: ê³¼ê±° ì„±ê³µí•œ ìš”ì•½ë¬¸ (í†¤ì•¤ë§¤ë„ˆ ë° ìŠ¤íƒ€ì¼ ì°¸ê³ )\n",
    "\n",
    "## ì‘ì„± ì›ì¹™\n",
    "1. **ì •ë³´ì˜ ê¹Šì´**: ì›ë³¸ ìë£Œì˜ ì‚¬ì‹¤ê³¼ ë””í…Œì¼ í™œìš©\n",
    "2. **ìŠ¤íƒ€ì¼ ì¼ê´€ì„±**: ì‘ì„± ì˜ˆì‹œì˜ í†¤ì•¤ë§¤ë„ˆ ì°¸ê³ \n",
    "3. **ë…ì°½ì„±**: ì˜ˆì‹œë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ê³  í•´ë‹¹ ë§¤ì¥ë§Œì˜ íŠ¹ì§• í‘œí˜„\n",
    "4. êµ¬ì¡°: ì œëª© 1ê°œ + ìš”ì•½ ë¬¸ì¥ 3ê°œ\n",
    "5. ê¸¸ì´: ê° ë¬¸ì¥ 40-60ì\n",
    "\n",
    "## ìš”ì•½ ë¬¸ì¥ êµ¬ì¡°\n",
    "- **1ë²ˆ ë¬¸ì¥**: ì…°í”„ ì² í•™ / ë¸Œëœë“œ ì •ì²´ì„±\n",
    "- **2ë²ˆ ë¬¸ì¥**: ì½”ìŠ¤ êµ¬ì„± / ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´\n",
    "- **3ë²ˆ ë¬¸ì¥**: ê³µê°„ íŠ¹ì§• / ë¯¸ì‹ ê²½í—˜\n",
    "\n",
    "## ì¶œë ¥ í˜•ì‹\n",
    "{{\n",
    "  \"shop_seq\": ìˆ«ì,\n",
    "  \"shop_name\": \"ë§¤ì¥ëª…\",\n",
    "  \"title\": \"ì œëª© (15-30ì)\",\n",
    "  \"summaries\": [\"ë¬¸ì¥1\", \"ë¬¸ì¥2\", \"ë¬¸ì¥3\"]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "generation_config = types.GenerateContentConfig(\n",
    "    temperature=0.5,\n",
    "    max_output_tokens=4096,\n",
    "    response_mime_type=\"application/json\"\n",
    ")\n",
    "\n",
    "print(f\"ğŸ¤– ëª¨ë¸: {MODEL_NAME} (Hybrid RAG)\\n\")\n",
    "\n",
    "\n",
    "def generate_summary_with_hybrid_rag(shop_seq, shop_name, collected_info):\n",
    "    \"\"\"\n",
    "    Hybrid RAG: ì›ë³¸ ì†ŒìŠ¤ + ìš”ì•½ë¬¸ ì˜ˆì‹œ ëª¨ë‘ í™œìš©\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ì›ë³¸ ì†ŒìŠ¤ ê²€ìƒ‰ (ë°°ê²½ ì§€ì‹)\n",
    "    similar_sources = retrieve_similar_sources(\n",
    "        query_text=collected_info,\n",
    "        collection=waiting_hotplace_sources,\n",
    "        top_k=2\n",
    "    )\n",
    "    \n",
    "    # 2. ìš”ì•½ë¬¸ ì˜ˆì‹œ ê²€ìƒ‰ (ìŠ¤íƒ€ì¼ ì°¸ê³ )\n",
    "    similar_examples = retrieve_similar_examples(\n",
    "        query_text=collected_info,\n",
    "        collection=waiting_hotplace_examples,\n",
    "        top_k=2\n",
    "    )\n",
    "    \n",
    "    # 3. í•˜ì´ë¸Œë¦¬ë“œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±\n",
    "    hybrid_context = format_hybrid_context(similar_sources, similar_examples)\n",
    "    \n",
    "    # 4. í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    user_prompt = f\"\"\"\n",
    "    {hybrid_context}\n",
    "\n",
    "    [ìƒì„±í•  ë§¤ì¥]\n",
    "    ë§¤ì¥ëª…: {shop_name}\n",
    "    Shop Seq: {shop_seq}\n",
    "\n",
    "    [ìˆ˜ì§‘ëœ ì •ë³´]\n",
    "    {collected_info}\n",
    "\n",
    "    ìœ„ ì›ë³¸ ìë£Œì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‘ì„± ì˜ˆì‹œì˜ ìŠ¤íƒ€ì¼ì„ ì°¸ê³ í•˜ì—¬\n",
    "    {shop_name} ë§¤ì¥ë§Œì˜ ê³ ìœ í•œ ìš”ì•½ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL_NAME,\n",
    "            contents=f\"{system_prompt}\\n\\n{user_prompt}\",\n",
    "            config=generation_config\n",
    "        )\n",
    "        \n",
    "        result_json = json.loads(response.text)\n",
    "        \n",
    "        usage_metadata = response.usage_metadata if hasattr(response, 'usage_metadata') else None\n",
    "        token_info = {}\n",
    "        if usage_metadata:\n",
    "            token_info = {\n",
    "                \"input_tokens\": usage_metadata.prompt_token_count,\n",
    "                \"output_tokens\": usage_metadata.candidates_token_count,\n",
    "                \"total_tokens\": usage_metadata.total_token_count\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"data\": result_json,\n",
    "            \"tokens\": token_info,\n",
    "            \"source_count\": len(similar_sources),\n",
    "            \"example_count\": len(similar_examples)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_type\": type(e).__name__,\n",
    "            \"message\": str(e),\n",
    "            \"tokens\": {},\n",
    "            \"source_count\": len(similar_sources),\n",
    "            \"example_count\": len(similar_examples)\n",
    "        }\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "all_results = []\n",
    "\n",
    "if MODE == \"single\":\n",
    "    print(f\"ğŸ” [{SHOP_NAME}] Hybrid RAG ê²€ìƒ‰ ì¤‘...\")\n",
    "    print(f\"   - ì›ë³¸ ì†ŒìŠ¤ ê²€ìƒ‰ (ë°°ê²½ ì§€ì‹)\")\n",
    "    print(f\"   - ìš”ì•½ë¬¸ ì˜ˆì‹œ ê²€ìƒ‰ (ìŠ¤íƒ€ì¼ ì°¸ê³ )\\n\")\n",
    "    \n",
    "    result = generate_summary_with_hybrid_rag(SHOP_SEQ, SHOP_NAME, collected_info)\n",
    "    \n",
    "    print(f\"   âœ… ì›ë³¸ ì†ŒìŠ¤: {result['source_count']}ê°œ\")\n",
    "    print(f\"   âœ… ìš”ì•½ë¬¸ ì˜ˆì‹œ: {result['example_count']}ê°œ\\n\")\n",
    "    print(f\"ğŸ“ ìš”ì•½ë¬¸ ìƒì„± ì¤‘...\\n\")\n",
    "    \n",
    "    if result[\"status\"] == \"success\":\n",
    "        result_json = result[\"data\"]\n",
    "        all_results.append(result_json)\n",
    "        \n",
    "        tokens = result.get(\"tokens\", {})\n",
    "        if tokens:\n",
    "            print(f\"ğŸ“Š í† í° ì‚¬ìš©ëŸ‰:\")\n",
    "            print(f\"   - Input:  {tokens.get('input_tokens', 0):,} tokens\")\n",
    "            print(f\"   - Output: {tokens.get('output_tokens', 0):,} tokens\")\n",
    "            print(f\"   - Total:  {tokens.get('total_tokens', 0):,} tokens\\n\")\n",
    "        \n",
    "        print(\"âœ… Hybrid RAG ìš”ì•½ë¬¸ ìƒì„± ì™„ë£Œ\\n\")\n",
    "        print(\"=\" * 80)\n",
    "        print(json.dumps(result_json, ensure_ascii=False, indent=2))\n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        print(f\"âŒ ì—ëŸ¬: {result['message']}\")\n",
    "\n",
    "elif MODE == \"multi\":\n",
    "    print(f\"ğŸ“ {len(SHOP_LIST)}ê°œ ë§¤ì¥ Hybrid RAG ì‹¤í–‰\\n\")\n",
    "    \n",
    "    for idx, shop in enumerate(SHOP_LIST, 1):\n",
    "        shop_seq = shop[\"shop_seq\"]\n",
    "        shop_name = shop[\"shop_name\"]\n",
    "        collected_info = shop[\"collected_info\"]\n",
    "        \n",
    "        print(f\"[{idx}/{len(SHOP_LIST)}] {shop_name}...\")\n",
    "        \n",
    "        result = generate_summary_with_hybrid_rag(shop_seq, shop_name, collected_info)\n",
    "        \n",
    "        if result[\"status\"] == \"success\":\n",
    "            all_results.append(result[\"data\"])\n",
    "            print(f\"   âœ… ì„±ê³µ | ì†ŒìŠ¤: {result['source_count']}ê°œ | ì˜ˆì‹œ: {result['example_count']}ê°œ\")\n",
    "        else:\n",
    "            print(f\"   âŒ ì‹¤íŒ¨: {result['message']}\")\n",
    "    \n",
    "    print(f\"\\nâœ… ì™„ë£Œ: {len(all_results)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… ì„¹ì…˜ 9-10: ê²€ì¦ ë° ì €ì¥\n",
    "\n",
    "(ê¸°ì¡´ main_rag.ipynbì˜ ì„¹ì…˜ 9-10ê³¼ ë™ì¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… ê²€ì¦ ë° ì €ì¥\")\n",
    "print(\"   (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼ - í•„ìš” ì‹œ ë³µì‚¬)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ ì™„ë£Œ!\n",
    "\n",
    "## 3ê°€ì§€ RAG ë°©ì‹ ì‚¬ìš© ê°€ì´ë“œ\n",
    "\n",
    "### ì–¸ì œ ì–´ë–¤ ë°©ì‹ì„ ì‚¬ìš©í• ê¹Œ?\n",
    "\n",
    "| ìƒí™© | ì¶”ì²œ ë°©ì‹ | ì´ìœ  |\n",
    "|------|-----------|------|\n",
    "| ì´ˆê¸° (ë°ì´í„° ì—†ìŒ) | Source-based (v4.0) | ì›ë³¸ ì†ŒìŠ¤ë§Œ ìˆì–´ë„ ì‘ë™ |\n",
    "| ìŠ¤íƒ€ì¼ ì¼ê´€ì„± ì¤‘ìš” | Example-based (v3.0) | ì˜ˆì‹œ í•™ìŠµìœ¼ë¡œ í†¤ì•¤ë§¤ë„ˆ í†µì¼ |\n",
    "| ìµœê³  í’ˆì§ˆ í•„ìš” | **Hybrid (v5.0)** | ì •ë³´ì˜ ê¹Šì´ + ìŠ¤íƒ€ì¼ ì¼ê´€ì„± |\n",
    "| ë¹„ìš©/ì†ë„ ê³ ë ¤ | Example-based (v3.0) | ê°€ì¥ ì ì€ í† í° ì‚¬ìš© |\n",
    "\n",
    "### ì ì§„ì  ê°œì„  ê²½ë¡œ\n",
    "\n",
    "```\n",
    "1ë‹¨ê³„: Example-based (v3.0)\n",
    "   â†“\n",
    "2ë‹¨ê³„: Source ë°ì´í„° ìˆ˜ì§‘ ë° ì¸ë±ì‹±\n",
    "   â†“\n",
    "3ë‹¨ê³„: Source-based (v4.0) í…ŒìŠ¤íŠ¸\n",
    "   â†“\n",
    "4ë‹¨ê³„: Hybrid (v5.0) ìµœì¢… ì ìš©\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
